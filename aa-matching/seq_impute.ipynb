{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq_impute.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3867ea732df642d5a2b8e04f126f45d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62767eeecf4d476295b22813a5234d72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cdba7ec13394fd69a82da6e5aff9109",
              "IPY_MODEL_32b479275fdd40d2b1bcab24c8c63271"
            ]
          }
        },
        "62767eeecf4d476295b22813a5234d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cdba7ec13394fd69a82da6e5aff9109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c047aaeece654e5f9e67dc8cf5d83728",
            "_dom_classes": [],
            "description": "  8%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 6082,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 509,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_348142ea9a3746e3a5dcba677fc2d326"
          }
        },
        "32b479275fdd40d2b1bcab24c8c63271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2005f8d7646e4031bda5ed8582af3e4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 509/6082 [12:26&lt;2:30:47,  1.62s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9db9653b0784e86a4b1c81436aba539"
          }
        },
        "c047aaeece654e5f9e67dc8cf5d83728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "348142ea9a3746e3a5dcba677fc2d326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2005f8d7646e4031bda5ed8582af3e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9db9653b0784e86a4b1c81436aba539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrMDiO-Jf2i7"
      },
      "source": [
        "pathloc = str(os.getcwd()) + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhFyahA6evcG",
        "outputId": "71b1b9f3-589b-4086-ebde-ff1a1504f088"
      },
      "source": [
        "import sys \n",
        "pathloc = '/content/drive/MyDrive/Colab Notebooks/dev/aa-matching/'\n",
        "if pathloc not in sys.path:\n",
        "    sys.path.append(pathloc)\n",
        "!pip install biopython"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.78)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YangouChfuRn"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import math\n",
        "import os\n",
        "import os.path\n",
        "from os import wait\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import aa_matching_msf as aa\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from functools import reduce\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Seq import Seq\n",
        "from Bio.Data.CodonTable import TranslationError\n",
        "from tqdm.notebook import trange, tqdm"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1GkIXTjf66P",
        "outputId": "5e02d0b1-bfb5-48b7-bcef-47950b88b8b1"
      },
      "source": [
        "aa_mm = aa.AAMatch(dbversion=3400)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n",
            "MSF files already downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCuGOt7zwfsj"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "###############################################################################\n",
        "#   SCRIPT NAME:    nuc_matching_msf.py\n",
        "#   DESCRIPTION:    Module for nucleotide matching functions\n",
        "#   OUTPUT:\n",
        "#   DATE:           September 01, 2020\n",
        "#\tLAST UPDATE:\tJanuary 11, 2021\n",
        "#\tREASON:\t\t\tAuto-alignment to coordinate system.\n",
        "#   AUTHOR:         Giovanni Biagini (dbiagini@tulane.edu ; GitHub: gbiagini)\n",
        "#   PI:             Loren Gragert, Ph.D.\n",
        "#   ORGANIZATION:   Tulane University School of Medicine\n",
        "#   NOTES:\t\t\tFIXME: Need to reduce redundancy through imports.\n",
        "###############################################################################\n",
        "\n",
        "import re\n",
        "import os.path\n",
        "from os import path\n",
        "import Bio\n",
        "from Bio import SeqIO\n",
        "from Bio import AlignIO\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Seq import Seq\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "\n",
        "class NucMatch():\n",
        "    # TODO (gbiagini) - wrap outer code in a main() function to avoid running\n",
        "    #  every time scripts are imported\n",
        "\n",
        "    def __init__(self, dbversion=3420, ungap=False):\n",
        "        # if ungap = True, use complete reference sequence\n",
        "        # if ungap = False, use gapped reference sequence\n",
        "        self.dbversion = dbversion\n",
        "        self.ungap = ungap\n",
        "        hlaProteinOffset = {\n",
        "            \"A\" : 0,\n",
        "            \"B\" : 0,\n",
        "            \"C\" : 0, \n",
        "            \"DRA\" : 0,\n",
        "            \"DRB1\" : 0,\n",
        "            \"DRB3\" : 0,\n",
        "            \"DRB4\" : 0,\n",
        "            \"DRB5\" : 0,\n",
        "            \"DQA1\" : 0,\n",
        "            \"DQB1\" : 0,\n",
        "            \"DPA1\" : 0,\n",
        "            \"DPB1\" : 0,\n",
        "        }\n",
        "\n",
        "        first_ten = {\n",
        "            \"A*01:01:01:01\": \"GGCTCCCACTCCATGAGGTATTTCTTCACA\",\n",
        "            \"B*07:02:01:01\": \"GGCTCCCACTCCATGAGGTATTTCTACACC\",\n",
        "            \"C*01:02:01:01\": \"TGCTCCCACTCCATGAAGTATTTCTTCACA\",\n",
        "            \"DRB1*01:01:01:01\": \"GGGGACACCCGACCACGTTTCTTGTGGCAG\",\n",
        "            \"DRB3*01:01:02:01\": \"GGGGACACCCGACCACGTTTCTTGGAGCTG\",\n",
        "            \"DRB4*01:01:01:01\": \"GGGGACACCCAACCACGTTTCTTGGAGCAG\",\n",
        "            \"DRB5*01:01:01:01\": \"GGGGACACCCGACCACGTTTCTTGCAGCAG\",\n",
        "            \"DQA1*01:01:01:01\": \"GAAGACATTGTGGCTGACCACGTTGCCTCT\",\n",
        "            \"DQB1*05:01:01:01\": \"AGAGACTCTCCCGAGGATTTCGTGTACCAG\",\n",
        "            \"DPA1*01:03:01:01\": \"ATCAAGGCGGACCATGTGTCAACTTATGCC\",\n",
        "            \"DPB1*01:01:01:01\": \"AGGGCCACTCCAGAGAATTACGTGTACCAG\"\n",
        "        }\n",
        "        refseq_full = {\n",
        "           \"A\" : \"A*01:01:01:01\",\n",
        "            \"B\" : \"B*07:02:01:01\",\n",
        "            \"C\" : \"C*01:02:01:01\",\n",
        "            \"DRB1\" : \"DRB1*01:01:01:01\",\n",
        "            \"DRB3\" : \"DRB3*01:01:02:01\",\n",
        "            \"DRB4\" : \"DRB4*01:01:01:01\",\n",
        "            \"DRB5\" : \"DRB5*01:01:01:01\",\n",
        "            \"DQA1\" : \"DQA1*01:01:01:01\",\n",
        "            \"DQB1\" : \"DQB1*05:01:01:01\",\n",
        "            \"DPA1\" : \"DPA1*01:03:01:01\",\n",
        "            \"DPB1\" : \"DPB1*01:01:01:01\",\n",
        "        }\n",
        "\n",
        "        refseq = {\n",
        "            \"A\" : \"A*01:01\",\n",
        "            \"B\" : \"B*07:02\",\n",
        "            \"C\" : \"C*01:02\",\n",
        "            \"DRB1\" : \"DRB1*01:01\",\n",
        "            \"DRB3\" : \"DRB3*01:01\",\n",
        "            \"DRB4\" : \"DRB4*01:01\",\n",
        "            \"DRB5\" : \"DRB5*01:01\",\n",
        "            \"DQA1\" : \"DQA1*01:01\",\n",
        "            \"DQB1\" : \"DQB1*05:01\",\n",
        "            \"DPA1\" : \"DPA1*01:03\",\n",
        "            \"DPB1\" : \"DPB1*01:01\",\n",
        "            }\n",
        "\n",
        "            # use only ARD positions\n",
        "        ard_start_pos = {\n",
        "            \"A\" : 1,\n",
        "            \"B\" : 1,\n",
        "            \"C\" : 1,\n",
        "            \"DRB1\" : 1,\n",
        "            \"DRB3\" : 1,\n",
        "            \"DRB4\" : 1,\n",
        "            \"DRB5\" : 1,\t\n",
        "            \"DQA1\" : 1,\n",
        "            \"DQB1\" : 1,\n",
        "            \"DPA1\" : 1,\n",
        "            \"DPB1\" : 1,\n",
        "        }\n",
        "        ard_end_pos = {\n",
        "            \"A\" : 182,\n",
        "            \"B\" : 182,\n",
        "            \"C\" : 182,\n",
        "            \"DRB1\" : 94,\n",
        "            \"DRB3\" : 94,\n",
        "            \"DRB4\" : 94,\n",
        "            \"DRB5\" : 94,\t\n",
        "            \"DQA1\" : 94,\n",
        "            \"DQB1\" : 95, #increased by 1\n",
        "            \"DPA1\" : 94,\n",
        "            \"DPB1\" : 94,\n",
        "        }\n",
        "\n",
        "        # lots of incomplete ARD sequences in IMGT/HLA\n",
        "        # this should be handled in reference alignment, not here\n",
        "        ard_start_pos_incomplete = {\n",
        "            \"A\" : 2, # A*02:50\n",
        "            \"B\" : 2, # B*07:30\n",
        "            \"C\" : 2, # C*01:10\n",
        "            \"DRB1\" : 7, # DRB1*08:19\n",
        "            \"DRB3\" : 2, # TBD\n",
        "            \"DRB4\" : 2, # TBD\n",
        "            \"DRB5\" : 2, # TBD\n",
        "            \"DQA1\" : 6, # DQA1*01:06\n",
        "            \"DQB1\" : 6, # DQB1*05:100\n",
        "            \"DPA1\" : 11, # DPA1*01:03:02\n",
        "            \"DPB1\" : 6, # DPB1*01:01:03\n",
        "        }\n",
        "        ard_end_pos_incomplete = {\n",
        "            \"A\" : 182, # A*02:50\n",
        "            \"B\" : 182, # B*07:30\n",
        "            \"C\" : 182, # C*01:10\n",
        "            \"DRB1\" : 92, # DRB1*08:19\n",
        "            \"DRB3\" : 2, # TBD\n",
        "            \"DRB4\" : 2, # TBD\n",
        "            \"DRB5\" : 2, # TBD\n",
        "            \"DQA1\" : 87, # DQA1*01:06\n",
        "            \"DQB1\" : 94, # DQB1*05:100\n",
        "            \"DPA1\" : 84, # DPA1*01:03:02\n",
        "            \"DPB1\" : 92, # DPB1*01:01:03\n",
        "        }\n",
        "\n",
        "        self.refseq_full = refseq_full\n",
        "        self.refseq = refseq\n",
        "        self.ard_start_pos = ard_start_pos\n",
        "        self.ard_end_pos = ard_end_pos\n",
        "        self.ard_start_pos_incomplete = ard_start_pos_incomplete\n",
        "        self.ard_end_pos_incomplete = ard_end_pos_incomplete\n",
        "        self.hlaProteinOffset = hlaProteinOffset\n",
        "        self.first_ten = first_ten\n",
        "        self.main()\n",
        "\n",
        "        if self.ungap == True:\n",
        "            self.remove_gap()\n",
        "\n",
        "    # generate a regular expression to find first ten residues of each locus\n",
        "    # ignoring '-' characters.\n",
        "    def regex_gen(self):\n",
        "        regexes = {}\n",
        "        for each in self.first_ten.keys():\n",
        "            regex = \"\"\n",
        "            for i in range(0, len(self.first_ten[each])):\n",
        "                regex += str(self.first_ten[each][i])+\"[^\"+self.first_ten[each]+\"]*?\"\n",
        "            regexes[each] = regex\n",
        "        return regexes\n",
        "\n",
        "    # Align the coordinate system as appropriate to the beginning of the mature\n",
        "    # protein sequence.\n",
        "    def coordinate(self, regex, sequence):\n",
        "        o = re.search(regex, str(sequence))\n",
        "        offset = o.start()\n",
        "        return offset\n",
        "\n",
        "    def getMatureProteinOffset(self, locus):\n",
        "            return self.hlaProteinOffset.get(locus, \"Invalid HLA Locus\")\n",
        "        \n",
        "    def adjust_end(self, multipleseq, loc, ard_start_pos, ard_start_pos_incomplete, ard_end_pos,\n",
        "                    ard_end_pos_incomplete, prev=0, prev_inc=0):\n",
        "        loc_full_allele = self.refseq_full[loc]\n",
        "        full_protein = multipleseq[id==loc_full_allele].seq\n",
        "        mature_protein = full_protein[self.getMatureProteinOffset(loc):]\n",
        "        start = ard_start_pos\n",
        "        end = ard_end_pos\n",
        "        start_inc = ard_start_pos_incomplete\n",
        "        end_inc = ard_end_pos_incomplete\n",
        "        count = mature_protein[start:end].count('-')\n",
        "        count_inc = mature_protein[start_inc:end_inc].count('-')\n",
        "\n",
        "        check = count - prev\n",
        "        check_inc = count_inc - prev_inc\n",
        "\n",
        "        if (check == 0): \n",
        "            new_end = end + (count-prev)\n",
        "            new_end_inc = end_inc + (count_inc-prev_inc)\n",
        "            newlist = [new_end, new_end_inc]\n",
        "            return newlist\n",
        "        else:\n",
        "            new_end = end + (count - prev)\n",
        "            prev = count\n",
        "            if (check_inc != 0):\n",
        "                new_end_inc = end_inc + (count_inc - prev_inc)\n",
        "                prev_inc = count_inc\n",
        "                return self.adjust_end(multipleseq, loc, start, start_inc, new_end,\n",
        "                                    new_end_inc, prev, prev_inc)\n",
        "            else:\n",
        "                new_end_inc = end_inc\n",
        "                return self.adjust_end(multipleseq, loc, start, start_inc, new_end,\n",
        "                                    new_end_inc, prev, prev_inc=0)\n",
        "\n",
        "    def remove_ins(self, loc_full_alseq):\n",
        "        # need to remove the inserts from the reference sequence to print into\n",
        "        # the IMGT/HLA .txt file\n",
        "        gapframe = pd.DataFrame.from_dict(loc_full_alseq, orient=\"index\")\n",
        "        droplist = []\n",
        "        for i, row in gapframe.iterrows():\n",
        "            if i == self.refseq[loc]:\n",
        "                for name, data in gapframe.iteritems():\n",
        "                    if data[i] == '-':\n",
        "                        droplist.append(name)\n",
        "                    else:\n",
        "                        continue\n",
        "            else:\n",
        "                continue\n",
        "        ungapframe = gapframe.drop(droplist, axis=1)\n",
        "        for j, jrow in ungapframe.iterrows():\n",
        "            jrow = jrow.to_string(header=False, index=False)\n",
        "            jrow = jrow.replace('\\n', '')\n",
        "            jrow = jrow.replace(' ', '')\n",
        "            loc_full_alseq[j] = jrow\n",
        "        \n",
        "        return loc_full_alseq\n",
        "\n",
        "    def reference(self, multipleseq, loc):\n",
        "        loc_full_allele = self.refseq_full[loc]\n",
        "        regexes = self.regex_gen()\n",
        "        mslist = [x for x in multipleseq if x.id == loc_full_allele]\n",
        "        loc_full_protein = mslist[0]\n",
        "        #loc_full_protein = multipleseq[id==loc_full_allele]\n",
        "        full_protein = loc_full_protein.seq\n",
        "        \n",
        "        # align coordinate system based on reference sequence.\n",
        "        # uses two field allele if full allele not present.\n",
        "        # does not overwrite full allele if present.\n",
        "        # necessary for earlier database versions.\n",
        "        offset = self.coordinate(regexes[self.refseq_full[loc]], full_protein)\n",
        "        self.hlaProteinOffset[loc] = offset\n",
        "\n",
        "        return\n",
        "\n",
        "    def adjust(self, multipleseq, loc):\n",
        "        # then adjust end position based on dashes.\n",
        "        new_end, new_end_inc = self.adjust_end(multipleseq, loc, self.ard_start_pos[loc],\n",
        "                                            self.ard_start_pos_incomplete[loc],\n",
        "                                            self.ard_end_pos[loc],\n",
        "                                            self.ard_end_pos_incomplete[loc],\n",
        "                                            prev=0, prev_inc=0)\n",
        "        self.ard_end_pos[loc] = new_end\n",
        "        self.ard_end_pos_incomplete[loc] = new_end_inc\n",
        "        return\n",
        "\n",
        "\n",
        "    def generate_IMGT(self, HLA_full_alseq):\n",
        "        outfile = open(\"./IMGT_HLA_Full_Protein_\" + str(self.dbversion) + \".txt\", \"w+\")\n",
        "        outfile.write(\"Allele\\tFull_Protein\\n\")\n",
        "        for allele_loctype in HLA_full_alseq:\n",
        "            outfile.write(\"HLA-\" + allele_loctype + \"\\t\" +\n",
        "                        str(HLA_full_alseq[allele_loctype]) + \"\\n\")\n",
        "        outfile.close()\n",
        "        return\n",
        "\n",
        "    def remove_gap(self):\n",
        "        loci =  ['A', 'B', 'C', 'DRB1', 'DRB3', 'DRB4', 'DRB5', 'DQA1', 'DQB1', 'DPA1', 'DPB1']\n",
        "        refgaps2 = {}\n",
        "        refgaps4 = {}\n",
        "        for locus in loci:\n",
        "            seq2 = str(self.HLA_seq[self.refseq[locus]].seq)\n",
        "            seq4 = str(self.HLA_full_allele[self.refseq_full[locus]].seq)\n",
        "            refgaps2[locus] = [i for i, ltr in enumerate(seq2) if ltr == '-']\n",
        "            refgaps4[locus] = [j for j, lttr in enumerate(seq4) if lttr == '-']\n",
        "        for x2 in self.HLA_seq.keys():\n",
        "            locus = x2.split('*')[0]\n",
        "            gapseq2 = str(self.HLA_seq[x2].seq)\n",
        "            seq2x = ''.join([gapseq2[i] for i in range(len(gapseq2)) if not(gapseq2[i] == '-' and (i in refgaps2[locus]))])\n",
        "            self.HLA_seq[x2].seq = Seq(seq2x)\n",
        "        for x4 in self.HLA_full_allele.keys():\n",
        "            locus = x4.split('*')[0]\n",
        "            gapseq4 = str(self.HLA_full_allele[x4].seq)\n",
        "            seq4x = ''.join([gapseq4[i] for i in range(len(gapseq4)) if not(gapseq4[i] == '-' and (i in refgaps4[locus]))])\n",
        "            self.HLA_full_allele[x4].seq = Seq(seq4x)\n",
        "        return\n",
        "\n",
        "    def main(self):\n",
        "        loci =  ['A', 'B', 'C', 'DRB1', 'DRB345', 'DQA1', 'DQB1', 'DPA1', 'DPB1']\n",
        "        self.HLA_full_allele = {} # Full four-field allele names\n",
        "        #self.HLA_full_alseq = {} # Only used for generating IMGTHLA files\n",
        "        self.HLA_seq = {} # Two-field\n",
        "        regex = '\\w*\\*\\d*\\:\\d*'\n",
        "        suffixes = [\"L\", \"S\", \"C\", \"A\", \"Q\", \"N\"]\n",
        "\n",
        "        for locus in loci:\n",
        "            loc_full_alseq = {}\n",
        "            seq_filename = \"{}nuc_msf/{}_nuc_{}.msf\".format(pathloc,locus,self.dbversion)\n",
        "            seq_filename = Path(seq_filename)\n",
        "            if path.exists(seq_filename) == False:\n",
        "                print(\"Downloading requested MSF nucleotide files for locus \" + locus + \"...\")\n",
        "                url = \"https://raw.githubusercontent.com/ANHIG/IMGTHLA/{}/msf/{}_nuc.msf\".format(self.dbversion, locus)\n",
        "                r = requests.get(url)\n",
        "                with open(seq_filename, 'wb') as f:\n",
        "                    f.write(r.content)\n",
        "            else: \n",
        "                print(\"MSF nucleotide files already downloaded\")\n",
        "            multipleseq = AlignIO.read(seq_filename, format=\"msf\")\n",
        "            \n",
        "            if locus == 'DRB345':\n",
        "                for loc in ['DRB3', 'DRB4', 'DRB5']:\n",
        "                    self.reference(multipleseq, loc)\n",
        "                    self.adjust(multipleseq, loc)\n",
        "            else: \n",
        "                self.reference(multipleseq, locus)\n",
        "                self.adjust(multipleseq, locus)\n",
        "\n",
        "            for record in multipleseq:\n",
        "                loc_full_allele = record.id\n",
        "                (loc,full_allele) = loc_full_allele.split(\"*\")\n",
        "                # append the suffix - needed for null alleles\n",
        "                # index starts at 1 since some loci characters are also suffixes\n",
        "                separator = loc_full_allele.find(\"*\")\n",
        "                if any(x in loc_full_allele[separator:] for x in suffixes):\n",
        "                    loc_two_field_allele = re.match(regex, loc_full_allele).group() + \\\n",
        "                                        loc_full_allele[-1]\n",
        "                else:\n",
        "                    loc_two_field_allele = re.match(regex, loc_full_allele).group()\n",
        "                full_protein = record.seq\n",
        "                nogap = full_protein\n",
        "\n",
        "                loc_full_alseq[loc_full_allele] = SeqRecord(nogap)\n",
        "\n",
        "                # skip missing sequences in IMGT/HLA file\n",
        "                if (len(full_protein) <10): # #NAME?\n",
        "                    print (\"Missing Sequence:\" + loc_full_allele)\n",
        "                    continue\n",
        "\n",
        "                mature_protein = full_protein[self.getMatureProteinOffset(loc):]\n",
        "                mrecord = SeqRecord(mature_protein)\n",
        "\n",
        "\n",
        "                # full allele name\n",
        "                self.HLA_full_allele[loc_full_allele] = mrecord\n",
        "\n",
        "                # don't overwrite two-field alleles with new sequences - more likely\n",
        "                # to be incomplete\n",
        "                if (loc_two_field_allele not in self.HLA_seq):\n",
        "                    self.HLA_seq[loc_two_field_allele] = mrecord\n",
        "\n",
        "                # print (HLA_seqrecord_dict[allele])\n",
        "                \n",
        "                # TODO - add feature annotation to SeqIO object\n",
        "                # https://biopython.org/wiki/SeqRecord\n",
        "                # e.g. - which allele contain Bw4/Bw6 epitopes, bind LILRB1, etc\n",
        "                # https://www.biostars.org/p/57549/\n",
        "\n",
        "                # print (HLA_seqrecord_dict[allele].seq)\n",
        "            \n",
        "            #!GB!# Commented out these two lines as well as the generate_IMGT()\n",
        "            # function call, since the process is intensive and does not need to be\n",
        "            #!GB!# run every time the code is used. Might should consider a switch to\n",
        "            # splitting a HLA_full_alseq DataFrame by locus and doing all of the work in\n",
        "            #!GB!# a single function definition.\n",
        "            #loc_full_alseq = remove_ins(loc_full_alseq)\n",
        "            #HLA_full_alseq.update(loc_full_alseq)\n",
        "\n",
        "        #generate_IMGT(HLA_full_alseq)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZx1XAmCz--A",
        "outputId": "f0c8a4b3-09b5-4f77-b4f0-b8140bffafda"
      },
      "source": [
        "nuc_mm = NucMatch(dbversion=3400)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n",
            "MSF nucleotide files already downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBCl-wprgOJH"
      },
      "source": [
        "\n",
        "class Impute():\n",
        "\n",
        "    suffixes = [\"L\", \"S\", \"C\", \"A\", \"Q\", \"N\"]\n",
        "\n",
        "    def __init__(self, suffixes=suffixes):\n",
        "        self.suffixes = suffixes    \n",
        "        self.main()\n",
        "        \n",
        "\n",
        "\n",
        "    def ungap(self, dataframe, refseq, loc):\n",
        "        # The dashes will be put at the beginning of every set of possible\n",
        "        # polymorphisms per residue.\n",
        "        # This is to prevent all of the '-' characters from being sent to front\n",
        "        i = 0\n",
        "        j = 0\n",
        "        new_cols = {}\n",
        "        tNum = 0\n",
        "\n",
        "        for column in dataframe:\n",
        "            num = int(column[1:])\n",
        "            if (column[0] == '-'):\n",
        "                if dataframe.loc[refseq[loc]][column] == 1:\n",
        "                    tNum = num\n",
        "                    i += 1\n",
        "                    j += 1\n",
        "                    new_col = (str(num - i) + '_INS_' + str(j))\n",
        "                    new_cols[column] = new_col\n",
        "            else:\n",
        "                if tNum == num:\n",
        "                    new_col = (str(column[0]) + str(num - i) + '_INS_' + str(j))\n",
        "                    new_cols[column] = new_col\n",
        "                else:\n",
        "                    new_col = (str(column[0]) + str(num - i))\n",
        "                    new_cols[column] = new_col\n",
        "\n",
        "        dataframe = dataframe.rename(columns=new_cols)\n",
        "        return dataframe\n",
        "\n",
        "\n",
        "    # returns list of indexes for dash characters in all sequences\n",
        "    def findIns(self, sequence):\n",
        "        seqIns = []\n",
        "        idx = sequence.find('-')\n",
        "        if (idx != -1):\n",
        "            seqIns.append(idx)\n",
        "        while (idx != -1):\n",
        "            idx = sequence.find('-', idx + 1)\n",
        "            if (idx != -1):\n",
        "                seqIns.append(idx)\n",
        "        return seqIns\n",
        "\n",
        "\n",
        "    # removes indexes if also in refseq[loc]\n",
        "    def checkComplete(self, sequence, seqIns):\n",
        "        checkIns = []\n",
        "        idx = sequence.find('-')\n",
        "        if (idx != -1):\n",
        "            checkIns.append(idx)\n",
        "        while (idx != -1):\n",
        "            idx = sequence.find('-', idx + 1)\n",
        "            if (idx != -1):\n",
        "                checkIns.append(idx)\n",
        "        checkIns = [x for x in checkIns if x not in seqIns]\n",
        "        return checkIns\n",
        "\n",
        "\n",
        "    # translate the nucleotide CDS into the amino acid sequence for all alleles\n",
        "    def translate_nuc(self, nuc_dict, seqIns):\n",
        "        translated = {}\n",
        "        incorrect = []\n",
        "        print(\"Tranlsation in progress...\")\n",
        "        for record in tqdm(nuc_dict.keys()):\n",
        "            nuc_seq = SeqRecord(Seq(nuc_dict[record]))\n",
        "            try:\n",
        "                aa_seq = SeqRecord(seq=nuc_seq.seq.translate(cds=False,\n",
        "                                                            to_stop=True))\n",
        "            except TranslationError:\n",
        "                incorrect.append(record)\n",
        "                new_seq = str(nuc_seq.seq)\n",
        "                new_sequel = []\n",
        "                new_sequel[:] = new_seq\n",
        "                new_sequel = [new_sequel[x]\n",
        "                            for x in range(0, len(new_sequel))\n",
        "                            if (x not in seqIns)]\n",
        "                nuc_seq = SeqRecord(Seq(''.join(new_sequel)))\n",
        "                aa_seq = SeqRecord(seq=nuc_seq.seq.translate(cds=False,\n",
        "                                                            to_stop=True))\n",
        "            translated[record] = aa_seq\n",
        "        return translated, incorrect\n",
        "\n",
        "    # add back gaps that are present in the reference (and other) alleles so that\n",
        "    # arrays are the same length\n",
        "    def correction(self, incorrect, translated, aaIns):\n",
        "        for each in incorrect:\n",
        "            for insert in aaIns:\n",
        "                translated[each] = translated[each][:insert] + '-' + \\\n",
        "                    translated[each][insert:]\n",
        "        return translated\n",
        "\n",
        "    # complete null alleles so that arrays are the same length\n",
        "    def finish_null(self, refseq, repDict):\n",
        "        suffixes = self.suffixes\n",
        "        removal = []\n",
        "        length = len(repDict[refseq])\n",
        "        for entry in repDict.keys():\n",
        "            separator = entry.find(\"*\")\n",
        "            if any(x in entry[separator:] for x in suffixes):\n",
        "                if (entry[-1] == \"N\"):\n",
        "                    trunk = len(repDict[entry])\n",
        "                    diff = length - trunk\n",
        "                    if (diff > 0):\n",
        "                        filler = \"*\" * diff\n",
        "                        fillist = list(filler)\n",
        "                        fix = repDict[entry] + fillist\n",
        "                        repDict[entry] = fix\n",
        "                else:\n",
        "                    removal.append(entry)\n",
        "        for bad in removal:\n",
        "            del repDict[bad]\n",
        "        return repDict\n",
        "\n",
        "\n",
        "    # Normalized Hamming distance is based on the number of sequence differences\n",
        "    #   divided by the number of sequence positions that are defined in both\n",
        "    #   sequences.\n",
        "    def distmat(self, locDict, test=True):\n",
        "        matDist = {}\n",
        "        print(\"Generating distance matrix...\")\n",
        "        for lKey in tqdm(locDict.keys()):\n",
        "            rDist = {}\n",
        "            for locKey in locDict.keys():\n",
        "                # needed for sequences with no overlaps in complete sequence\n",
        "                i = 1\n",
        "                diff = 0\n",
        "                if test:\n",
        "                    x = locDict[lKey]\n",
        "                    y = locDict[locKey]\n",
        "\n",
        "                    # compare sequences position-to-position\n",
        "                    for j in range(0, len(x)):\n",
        "                        if (x[j] != '-') and (y[j] != '-'):\n",
        "                            if (x[j] == y[j]): \n",
        "                                i += 1\n",
        "                            else:\n",
        "                                i += 1\n",
        "                                diff += 1\n",
        "                    rDist[locKey] = diff/i\n",
        "                else:\n",
        "                    if (lKey != locKey):\n",
        "                        x = locDict[lKey]\n",
        "                        y = locDict[locKey]\n",
        "\n",
        "                        # compare sequences position-to-position\n",
        "                        for j in range(0, len(x)):\n",
        "                            if (x[j] == '-') or (y[j] == '-'):\n",
        "                                continue\n",
        "                            else:\n",
        "                                if (x[j] == y[j]): \n",
        "                                    i += 1\n",
        "                                else:\n",
        "                                    i += 1\n",
        "                                    diff += 1\n",
        "                        rDist[locKey] = diff/i\n",
        "            matDist[lKey] = rDist\n",
        "        disFrame = pd.DataFrame.from_dict(matDist)\n",
        "        return disFrame\n",
        "\n",
        "    # Recursive algorithm for nearest 10 neighbor voting for sequence inference.    \n",
        "    def seqvote(self, rVal, rKey, disFrame, locDict, start):\n",
        "        rVal = rVal - 1\n",
        "        votes = {}\n",
        "        topten = {}\n",
        "        new_val = '-'\n",
        "        for n in list(disFrame.columns[start:start+10]):\n",
        "            topten[n] = disFrame.loc[rKey][n]\n",
        "\n",
        "        for neighbor in topten.keys():\n",
        "            n_acid = locDict[neighbor][rVal]\n",
        "            if (n_acid not in votes.keys() and n_acid != \"-\"):\n",
        "                votes[n_acid] = -abs(float(topten[neighbor]))\n",
        "            elif (n_acid == \"-\"):\n",
        "                next\n",
        "            # for additional votes for a single position, add value\n",
        "            # to increase the likelihood of selection\n",
        "            else:\n",
        "                votes[n_acid] += abs(float(topten[neighbor]))\n",
        "\n",
        "            try:\n",
        "                new_val = max(votes, key = lambda x: votes[x])\n",
        "            except ValueError:\n",
        "                start += 10\n",
        "                return self.seqvote(rVal, rKey, disFrame, locDict, start)\n",
        "        return new_val\n",
        "\n",
        "    # nearest 10 vote based on distance matrix\n",
        "    # TODO (gbiagini) - this function is not yet complete\n",
        "    def nearest10(self, loc, locDict, disFrame, rPos):\n",
        "        disFrame = disFrame.filter(regex=\".*[^NQLSCA]$\", axis=1)\n",
        "        with open(pathloc + \"data/nearest/{}_topten.txt\".format(loc), \"w+\") as handle:\n",
        "            handle.write(\"NEAREST 10 NEIGHBORS FOR EACH IMPUTED ALLELE + \\n\")\n",
        "            handle.write(\"Format for neighbors is $ALLELE (HamDist for NA Seq)\\n\")\n",
        "            print(\"Nearest 10 imputation...\")\n",
        "            for rKey in tqdm(rPos.keys()):\n",
        "                disFrame = disFrame.sort_values(by=rKey, axis=1, ignore_index=False)\n",
        "                # pull top 10 closest alleles\n",
        "                handle.write(\"Imputed allele:\\t\\t\\t\\t\" + rKey + \"\\n\")\n",
        "                topten = {}\n",
        "                if str(disFrame.columns[0]) != rKey:\n",
        "                    i = 0\n",
        "                    for n in list(disFrame.columns[0:10]):\n",
        "                        i += 1\n",
        "                        topten[n] = disFrame.loc[rKey][n]\n",
        "                        handle.write(\"Neighbor #\" + str(i) + \":\\t\\t\\t\\t\" + n + \" (\" +\n",
        "                                    str(topten[n]) + \")\\n\")\n",
        "                        start = 0\n",
        "                else:\n",
        "                    i = 0\n",
        "                    for n in list(disFrame.columns[1:11]):\n",
        "                        i += 1\n",
        "                        topten[n] = disFrame.loc[rKey][n]\n",
        "                        handle.write(\"Neighbor #\" + str(i) + \":\\t\\t\\t\\t\" + n + \" (\" +\n",
        "                                    str(topten[n]) + \")\\n\")\n",
        "                        start = 1\n",
        "                # infers sequence from nearest 10 neighbor vote\n",
        "                #!# if all 10 nearest neighbors have '-' at a position,\n",
        "                # the search expands to other positions\n",
        "                for rVal in rPos[rKey]:\n",
        "                    new_val = self.seqvote(rVal, rKey, disFrame, locDict, start)\n",
        "\n",
        "                    locDict[rKey] = locDict[rKey][:rVal] + \\\n",
        "                                new_val + locDict[rKey][rVal + 1:]\n",
        "        return locDict\n",
        "\n",
        "    def impute(self, loc, locDict, refseq, aaDict):\n",
        "        seqIns = self.findIns(locDict[refseq])\n",
        "        aaIns = self.findIns(str(aaDict[refseq].seq))\n",
        "        #recompute = True\n",
        "        if os.path.isfile(\"{}data/locdist/{}.csv\".format(pathloc,loc)):\n",
        "            recompute = False\n",
        "        else:\n",
        "            recompute = True\n",
        "        if recompute:\n",
        "            # TODO (gbiagini) - modify this to simply update previous distance\n",
        "            #  matrix, rather than re-do the entire computation\n",
        "            print(\"New alleles detected - must generate distance matrix!\")\n",
        "            replacePos = {}\n",
        "            binDict = {}\n",
        "            \n",
        "            for key in locDict.keys():\n",
        "                replacePos[key] = self.checkComplete(locDict[key], seqIns)\n",
        "\n",
        "            disFrame = self.distmat(locDict)\n",
        "            disFrame.to_csv(pathloc+\"data/locdist/{}.csv\".format(loc))\n",
        "            rPos = {r: replacePos[r] for r in replacePos.keys() if\n",
        "                    (len(replacePos[r]) != 0)}\n",
        "            del(replacePos)\n",
        "            \n",
        "        else:\n",
        "            replacePos = {}\n",
        "            for key in locDict.keys():\n",
        "                    replacePos[key] = self.checkComplete(locDict[key], seqIns)\n",
        "            rPos = {r: replacePos[r] for r in replacePos.keys() if\n",
        "                    (len(replacePos[r]) != 0)}\n",
        "            del (replacePos)\n",
        "\n",
        "            # TODO (gbiagini) - Need to fix this for situations in which the\n",
        "            #  distance matrix is regenerated (make index_col = 0)\n",
        "\n",
        "            # Modified to use complete distance matrix instead of previously used\n",
        "            #   exclusionary distance matrix\n",
        "            disFrame = pd.read_csv(pathloc+\"data/locdist/{}.csv\".format(loc), index_col=0)\n",
        "\n",
        "        disFrame = disFrame.transpose()\n",
        "        locDict = self.nearest10(loc, locDict, disFrame, rPos)\n",
        "        locDict, incorrect = self.translate_nuc(locDict, seqIns)\n",
        "        del(disFrame)\n",
        "        translated = self.correction(incorrect, locDict, aaIns)\n",
        "        return translated\n",
        "        \n",
        "    def main(self):\n",
        "        aaDict = aa_mm.HLA_full_allele\n",
        "        refseq = nuc_mm.refseq_full\n",
        "        HLA_seq = nuc_mm.HLA_full_allele\n",
        "        for loc in aa_mm.refseq:\n",
        "            #if loc in ['A', 'B', 'C', 'DRB1', 'DRB3']:\n",
        "                #continue\n",
        "            print(\"Processing locus \" + loc + \"...\")\n",
        "            locDict = {newKey: str(HLA_seq[newKey].seq) for newKey in HLA_seq.keys()}\n",
        "            newDict = {locKey: locDict[locKey] for locKey in locDict.keys() if (\n",
        "                locKey.split('*')[0] == loc)}\n",
        "            locDict = newDict\n",
        "            del (newDict)\n",
        "            imputed = self.impute(loc, locDict, refseq[loc], aaDict)\n",
        "            # creates list from sequence strings for Pandas dataframe\n",
        "            repDict = {repKey: list(imputed[repKey]) for repKey in imputed.keys()}\n",
        "            del(imputed)\n",
        "            repDict = self.finish_null(refseq[loc], repDict)\n",
        "            impnew = {iKey: ''.join(repDict[iKey]) for iKey in repDict.keys()}\n",
        "            my_records = []\n",
        "            for pkey in impnew.keys():\n",
        "                record = SeqRecord(\n",
        "                    Seq(impnew[pkey]),\n",
        "                    id=pkey,\n",
        "                )\n",
        "                my_records.append(record)\n",
        "            SeqIO.write(my_records, \"{}ifasta/{}_{}.fasta\".format(pathloc,loc,nuc_mm.dbversion), \"fasta\")\n",
        "\n",
        "            #repFrame = pd.DataFrame.from_dict(repDict)\n",
        "            #repFrame = repFrame.transpose()\n",
        "            # repFrame = pd.get_dummies(repFrame, prefix_sep='')\n",
        "            # lambda function to rename columns with string character first then\n",
        "            # position\n",
        "            #repFrame = repFrame.rename(\n",
        "            #   mapper=(lambda x: (str(x[-1]) + str(int(x[:-1]) + 1))), axis=1)\n",
        "            #repFrame.index.names = ['allele']\n",
        "            #repFrame = self.ungap(repFrame, refseq, loc)\n",
        "            #repFrame.to_csv(pathloc+\"imputed/{}_imputed.csv\".format(loc), index=True)\n",
        "            #print(\"Done with locus {}\".format(loc))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "3867ea732df642d5a2b8e04f126f45d0",
            "62767eeecf4d476295b22813a5234d72",
            "5cdba7ec13394fd69a82da6e5aff9109",
            "32b479275fdd40d2b1bcab24c8c63271",
            "c047aaeece654e5f9e67dc8cf5d83728",
            "348142ea9a3746e3a5dcba677fc2d326",
            "2005f8d7646e4031bda5ed8582af3e4d",
            "b9db9653b0784e86a4b1c81436aba539"
          ]
        },
        "id": "3X62qVpklqy3",
        "outputId": "1bfa9692-c226-4594-88e5-ba4434e81cea"
      },
      "source": [
        "Impute()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing locus A...\n",
            "New alleles detected - must generate distance matrix!\n",
            "Generating distance matrix...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3867ea732df642d5a2b8e04f126f45d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6082.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81atenKDFaNc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}