{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rf_sero.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"metadata":{"interpreter":{"hash":"bab016364d1038d8da29e67805d1a3377d41c5891bd8e13f5bd752f87e562a16"}},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"WxiDnGZw6OGt","colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"status":"error","timestamp":1618164078721,"user_tz":300,"elapsed":52373,"user":{"displayName":"David Biagini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPXNEuCDO4MZZrcNt32EOIZqfbB4_eLV0HcOFoOw=s64","userId":"18170855662239852923"}},"outputId":"ffbb6e50-ec14-4718-efcb-d3bde8f7d93d"},"source":["from google.colab import drive\n","from fastai.imports import *\n","from pathlib import Path\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/Colab Notebooks/dev/\"\n","base_dir = root_dir + 'nn-sero-pytorch/randomforest/'\n","path = Path(base_dir)\n","\n","!pip install lime"],"execution_count":2,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6ae3720c3c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/My Drive/Colab Notebooks/dev/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'nn-sero-pytorch/randomforest/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"dDKTGlbqnwLg"},"source":["from pathlib import Path\n","\n","root_dir = '../'\n","base_dir = root_dir + 'randomforest/'\n","path = Path(base_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MmQviheFLszE"},"source":["import pandas as pd\n","import numpy as np\n","import sys\n","import math\n","import lime\n","import lime.lime_tabular\n","from tqdm import tqdm\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","\n","def metrics(print_all='no'):\n","    loci = ['A', 'B', 'C', 'DQB1', 'DRB1']\n","    #loci = ['A']\n","\n","    NN_dir = '../'\n","\n","    # function to check if value can be an integer - to eliminate excess characters from serology labels\n","    def checkInt(x):\n","        try:\n","            int(x)\n","            return True\n","        except ValueError:\n","            return False\n","\n","    concordances = {}\n","\n","    for loc in loci:\n","        newDict = {}\n","        simDict = {}\n","        diffDict = {}\n","        oldPredict = {}\n","        newPredict = {}\n","        oldPredFile = Path(NN_dir + \"old-predictions/\" + loc + \".chile\")\n","        newPreds = pd.read_csv(base_dir + \"predictions/\" + loc + \"_predictions.csv\")\n","        newPreds = newPreds.set_index('allele')\n","        newPreds = newPreds.to_dict()\n","        newPredict = newPreds[\"serology\"]\n","        for nKey in newPredict.keys():\n","            adjustMe = newPredict[nKey]\n","            adjustMe = adjustMe.replace('[','')\n","            adjustMe = adjustMe.replace(']','')\n","            adjustMe = adjustMe.replace(' ','')\n","            adjustMe = adjustMe.replace(\"'\",'')\n","            adjustMe = adjustMe.split(',')\n","            newPredict[nKey] = [x.strip('a') for x in adjustMe if checkInt(x)]\n","        with open(oldPredFile, \"r\") as handle:\n","            for line in handle:\n","                if line.find('%') == -1:\n","                    next\n","                else:\n","                    line = line.split()\n","                    if line == []:\n","                        next\n","                    else:\n","                        line[:] = [x for x in line if (x != '[100.00%]')]\n","                        allele = loc + \"*\" + str(line[0][:-1])\n","                        oldPredict[allele] = line[1:]\n","\n","\n","        for each in oldPredict.keys():\n","            allDict = {}\n","            allDict[\"Allele\"] = each\n","            allDict[\"Old Assignment\"] = oldPredict[each]\n","            if each not in newPredict.keys():\n","                next\n","            else:\n","                allDict[\"New Assignment\"] = newPredict[each]\n","                if set(newPredict[each]) != set(oldPredict[each]):\n","                    diffDict[each] = allDict\n","                elif set(newPredict[each]) == set(oldPredict[each]):\n","                    simDict[each] = allDict\n","        diffFrame = pd.DataFrame.from_dict(diffDict)\n","        diffFrame = diffFrame.transpose()\n","        diffFrame.to_csv(base_dir + \"comparison/\" + loc + \"_compfile.csv\", index=False)\n","        simFrame = pd.DataFrame.from_dict(simDict)\n","        simFrame = simFrame.transpose()\n","        simFrame.to_csv(base_dir + \"comparison/\" + loc + \"_similar.csv\", index=False)\n","        \n","\n","        for allele in newPredict.keys():\n","            allDict = {}\n","            allDict[\"Allele\"] = allele\n","            allDict[\"Serologic Assignment\"] = newPredict[allele]\n","            if allele not in oldPredict.keys():\n","                newDict[allele] = allDict\n","        newFrame = pd.DataFrame.from_dict(simDict)\n","        newFrame = newFrame.transpose()\n","        newFrame.to_csv(base_dir + \"comparison/\" + loc + \"_newsies.csv\", index=False)\n","\n","        simLen = len(simFrame)\n","        diffLen = len(diffFrame)\n","        with open(base_dir + \"comparison/\" + loc + \"_concordance.txt\", \"w+\") as fhandle:\n","            fhandle.write(\"HLA-\" +loc+ \" Similar: \" + str(simLen))\n","            fhandle.write(\"HLA-\" +loc+ \" Different: \" + str(diffLen))\n","            concordance = (simLen / (simLen + diffLen)) * 100\n","            concordances[loc] = concordance\n","            fhandle.write(\"HLA-\" +loc+ \" Concordance: \" + str(concordance) + \"%\")\n","            if print_all == \"yes\":\n","                print(\"HLA-\" +loc+ \" Similar: \" + str(simLen))\n","                print(\"HLA-\" +loc+ \" Different: \" + str(diffLen))\n","                print(\"HLA-\" +loc+ \" Concordance: \" + str(concordance) + \"%\")\n","    return concordances\n","\n","#main(print_all=\"yes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-OE6SumgONm5"},"source":["np.set_printoptions(threshold=sys.maxsize)\n","\n","def one_hot_decode(df):\n","\tdf['serology']=''\n","\n","\tfor col in df.columns:\n","\t\tdf.loc[df[col]==1,'serology'] = df['serology']+col+';'\n","\n","\treturn df\n","\n","def fix_data(uniques, data, loc, iset, ident):\n","  sero = {}\n","  for row in data.itertuples(name='Pandas'):\n","    sero[row.allele] = str(row.serology)\n","    #sero[row[1]] = str(row[-1])\n","\t\n","  data = data.drop('serology', axis=1)\n","\n","  for key in sero.keys():\n","    '''\n","  \t# not applicable for old_sets train/test\n","    if (sero[key].find(';') != -1):\n","      sero[key] = sero[key].replace('a','')\n","      sero[key] = sero[key].split(';')\n","    else:\n","      sero[key] = sero[key].replace('a','')\n","      sero[key] = [sero[key]]\n","    '''\n","\n","    #for old_sets train/test\n","    sero[key] = sero[key].split(' ')\n","    \n","    for x in sero[key]:\n","      if (x not in uniques):\n","        uniques.append(x)\n","      else:\n","        continue\n","\n","  uniques = list(map(int, uniques))\n","  uniques.sort()\n","  uniques = list(map(str, uniques))\n","  \n","  for y in uniques:\n","    data[y] = 0\n","\n","  one_sero = {}\n","  for key in sero.keys():\n","    one_sero[key] = { some_key : (\"1\" if (some_key in sero[key]) else \"0\")\n","\t\t                  for some_key in uniques }\n","  one_df = pd.DataFrame.from_dict(one_sero)\n","  one_df = one_df.transpose()\n","  one_df.index.name = \"allele\"\n","  data = data.set_index('allele')\n","  data.update(one_df, overwrite=True)\n","  data.to_csv(base_dir + 'randfor/'+iset+'/'+loc+'_'+ident+'.csv', index=True)\n","  return data, uniques\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFXrjuPaKmln","outputId":"252a7877-966f-49d8-8a6a-50584bcddce6"},"source":["#RSEED = 0\n","\n","pre_concord = metrics()\n","\n","loci = [\"A\", \"B\", \"C\", \"DQB1\", \"DRB1\"]\n","print(\"Predicting...\")\n","for loc in tqdm(loci):\n","  uniques = []\n","  print(loc)\n","  features = pd.read_csv(base_dir + \"training/\" + loc + \"_train.csv\")\n","  #features['serology'] = features['serology'].apply(lambda x: x.replace('a','').replace(';',' '))\n","  features, sers = fix_data(uniques, features,loc,iset='training',ident='train')\n","  vfeatures = pd.read_csv(base_dir + \"training/\" + loc + \"_validation.csv\")\n","  #vfeatures['serology'] = vfeatures['serology'].apply(lambda x: x.replace('a','').replace(';',' '))\n","  vfeatures, vsers = fix_data(uniques, vfeatures,loc,iset='training',ident='validation')\n","  test = pd.read_csv(base_dir + \"testing/\" + loc + \"_test.csv\")\n","  test = test.drop('serology', axis=1)\n","  test.to_csv(base_dir + 'randfor/testing/'+loc+'_test.csv', index=True)\n","\n","  features = features.append(vfeatures)\n","  labels = np.array(features[sers])\n","  features = features.drop(sers, axis=1)\n","  features = features.reset_index()\n","  indices = features[\"allele\"]\n","  indices = list(indices)\n","  features = features.drop('allele', axis=1)\n","  feature_list = list(features.columns)\n","  n_features = len(feature_list)\n","  maxfeat = int(math.sqrt(n_features))\n","\n","  features = np.array(features)\n","  labels[labels!=labels]='0'\n","  features[features!=features]='0'\n","  features = features.astype(int)\n","  labels = labels.astype(int)\n","\n","  test_idcs = test['allele']\n","  test = test.drop('allele', axis=1)\n","  #print(test.head(100))\n","  test_list = list(test.columns)\n","  test = np.array(test)\n","  test[test!=test]='0'\n","  test = test.astype(int)\n","\n","  forest = RandomForestClassifier(n_estimators=500, bootstrap=True, max_features=maxfeat, n_jobs=-1)\n","  multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\n","  multi_target_forest.fit(features,labels)\n","  predictions = multi_target_forest.predict(test)\n","\n","  ind_labels = [str(x) for x in sers]\n","  #explainer = lime.lime_tabular.LimeTabularExplainer(features,feature_names=feature_list,class_names=ind_labels,kernel_width=5)\n","  #for rowexp in range(0,2):\n","  #  exp = explainer.explain_instance(test[rowexp], multi_target_forest.predict_proba, num_features=maxfeat)\n","  #  exp.show_in_notebook(show_table=True)\n","\n","  preds_output = pd.DataFrame(predictions, index=test_idcs, columns=ind_labels)\n","  preds_output = one_hot_decode(preds_output)\n","  preds_output = preds_output.drop(ind_labels, axis=1)\n","  preds_output.index.name = 'allele'\n","  preds_output = preds_output.apply(lambda x: str((x['serology'].split(';'))[:-1]), result_type='broadcast', axis=1)\n","  #print(preds_output)\n","  preds_output.to_csv(base_dir + 'predictions/'+loc+'_predictions.csv', index=True)\n","\n","print(\"Done.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Predicting...\n","A\n"],"name":"stdout"},{"output_type":"stream","text":[" 20%|██        | 1/5 [00:11<00:47, 11.76s/it]"],"name":"stderr"},{"output_type":"stream","text":["B\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|████      | 2/5 [00:30<00:48, 16.05s/it]"],"name":"stderr"},{"output_type":"stream","text":["C\n"],"name":"stdout"},{"output_type":"stream","text":["/home/gbiagini/miniconda3/envs/nn-sero/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1793) have mixed types.Specify dtype option on import or set low_memory=False.\n","  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"," 60%|██████    | 3/5 [00:36<00:22, 11.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["DQB1\n"],"name":"stdout"},{"output_type":"stream","text":[" 80%|████████  | 4/5 [00:40<00:08,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["DRB1\n"],"name":"stdout"},{"output_type":"stream","text":["/home/gbiagini/miniconda3/envs/nn-sero/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (812) have mixed types.Specify dtype option on import or set low_memory=False.\n","  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","100%|██████████| 5/5 [00:47<00:00,  9.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["Done.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ggEURdcKyWC","outputId":"9051b0d9-b8cd-436d-d5ef-45415b32469e"},"source":["post_concord = metrics()\n","\n","for loc in loci:\n","\tprint(loc + \" Concordance:\\t\\t\\t\\t\" + str(post_concord[loc])[:5] + \"%\")\n","\tchange = post_concord[loc] - pre_concord[loc]\n","\tprint(\"% Change:\\t\\t\\t\\t\" + str(change)[:5] + \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["A Concordance:\t\t\t\t92.78%\n","% Change:\t\t\t\t-1.59%\n","B Concordance:\t\t\t\t83.06%\n","% Change:\t\t\t\t0.088%\n","C Concordance:\t\t\t\t67.88%\n","% Change:\t\t\t\t-1.29%\n","DQB1 Concordance:\t\t\t\t87.31%\n","% Change:\t\t\t\t0.362%\n","DRB1 Concordance:\t\t\t\t89.84%\n","% Change:\t\t\t\t-0.09%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PjeCUnkq02IY","outputId":"1a8e90ca-fa88-4f35-c137-fab9b36436b1"},"source":["importances = multi_target_forest.feature_importances_\n","std = np.std([tree.feature_importances_ for tree in multi_target_forest.estimators_],\n","             axis=0)\n","indices = np.argsort(importances)[::-1]\n","\n","# Print the feature ranking\n","print(\"Feature ranking:\")\n","\n","for f in range(X.shape[1]):\n","    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n","\n","# Plot the impurity-based feature importances of the forest\n","plt.figure()\n","plt.title(\"Feature importances\")\n","plt.bar(range(X.shape[1]), importances[indices],\n","        color=\"r\", yerr=std[indices], align=\"center\")\n","plt.xticks(range(X.shape[1]), indices)\n","plt.xlim([-1, X.shape[1]])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NotFittedError","evalue":"This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-86240b53f1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n\u001b[1;32m      3\u001b[0m              axis=0)\n\u001b[1;32m      4\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/nn-sero/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \"\"\"\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         all_importances = Parallel(n_jobs=self.n_jobs,\n","\u001b[0;32m~/miniconda3/envs/nn-sero/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/nn-sero/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."]}]},{"cell_type":"code","metadata":{"id":"F40gNQO1yjVc"},"source":[""],"execution_count":null,"outputs":[]}]}