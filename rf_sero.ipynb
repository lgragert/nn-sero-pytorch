{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b30cqa5JiET"
      },
      "source": [
        "# Random Forest for Serology Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGaDga8MXUX7"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wcVlZt3mIokC"
      },
      "outputs": [],
      "source": [
        "colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvW1gg-bIkwQ",
        "outputId": "c6c34c11-fd8e-4dc9-db71-41b2fa048a40"
      },
      "outputs": [],
      "source": [
        "if colab == True:\n",
        "    from pathlib import Path\n",
        "    root_dir = \"/content/drive/MyDrive/dev/\"\n",
        "    base_dir = root_dir + 'nn-sero-pytorch/randomforest/'\n",
        "    path = Path(base_dir)\n",
        "    NN_dir = root_dir + 'nn-sero-pytorch/'\n",
        "\n",
        "    !pip install lime\n",
        "else:\n",
        "    from pathlib import Path\n",
        "    root_dir = './'\n",
        "    base_dir = root_dir + 'randomforest/'\n",
        "    path = Path(base_dir)\n",
        "    NN_dir = './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7hctgPvqkKn"
      },
      "source": [
        "## Random Forest Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZHlTkNIXZQ_"
      },
      "source": [
        "### Prior Concordance Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eeT9MbRvI7a_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import math\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from collections import defaultdict\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklearn.inspection import permutation_importance\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def metrics(print_all='no'):\n",
        "    loci = ['A', 'B', 'C', 'DQB1', 'DRB1']\n",
        "    #loci = ['A']\n",
        "\n",
        "    # function to check if value can be an integer - to eliminate excess characters from serology labels\n",
        "    def checkInt(x):\n",
        "        try:\n",
        "            int(x)\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "\n",
        "    concordances = {}\n",
        "\n",
        "    for loc in loci:\n",
        "        newDict = {}\n",
        "        simDict = {}\n",
        "        diffDict = {}\n",
        "        oldPredict = {}\n",
        "        newPredict = {}\n",
        "        oldPredFile = Path(NN_dir + \"old-predictions/\" + loc + \".chile\")\n",
        "        newPreds = pd.read_csv(base_dir + \"predictions/\" + loc + \"_predictions.csv\")\n",
        "        newPreds = newPreds.set_index('allele')\n",
        "        newPreds = newPreds.to_dict()\n",
        "        newPredict = newPreds[\"serology\"]\n",
        "        for nKey in newPredict.keys():\n",
        "            adjustMe = newPredict[nKey]\n",
        "            adjustMe = adjustMe.replace('[','')\n",
        "            adjustMe = adjustMe.replace(']','')\n",
        "            adjustMe = adjustMe.replace(' ','')\n",
        "            adjustMe = adjustMe.replace(\"'\",'')\n",
        "            adjustMe = adjustMe.split(',')\n",
        "            newPredict[nKey] = [x.strip('a') for x in adjustMe if checkInt(x)]\n",
        "        with open(oldPredFile, \"r\") as handle:\n",
        "            for line in handle:\n",
        "                if line.find('%') == -1:\n",
        "                    next\n",
        "                else:\n",
        "                    line = line.split()\n",
        "                    if line == []:\n",
        "                        next\n",
        "                    else:\n",
        "                        line[:] = [x for x in line if (x != '[100.00%]')]\n",
        "                        allele = loc + \"*\" + str(line[0][:-1])\n",
        "                        oldPredict[allele] = line[1:]\n",
        "\n",
        "        if loc == 'C':\n",
        "            skipc = ['C*01', 'C*02', 'C*03', 'C*04', 'C*05', 'C*06', 'C*07', 'C*08']\n",
        "            oldPredict = {k:v for k,v in oldPredict.items() if k[:4] in skipc}\n",
        "            newPredict = {k:v for k,v in newPredict.items() if k[:4] in skipc}\n",
        "\n",
        "\n",
        "        for each in oldPredict.keys():\n",
        "            allDict = {}\n",
        "            allDict[\"Allele\"] = each\n",
        "            allDict[\"Old Assignment\"] = oldPredict[each]\n",
        "            if each not in newPredict.keys():\n",
        "                next\n",
        "            else:\n",
        "                allDict[\"New Assignment\"] = newPredict[each]\n",
        "                if set(newPredict[each]) != set(oldPredict[each]):\n",
        "                    diffDict[each] = allDict\n",
        "                elif set(newPredict[each]) == set(oldPredict[each]):\n",
        "                    simDict[each] = allDict\n",
        "        diffFrame = pd.DataFrame.from_dict(diffDict)\n",
        "        diffFrame = diffFrame.transpose()\n",
        "        diffFrame.to_csv(base_dir + \"comparison/\" + loc + \"_compfile.csv\", index=False)\n",
        "        simFrame = pd.DataFrame.from_dict(simDict)\n",
        "        simFrame = simFrame.transpose()\n",
        "        simFrame.to_csv(base_dir + \"comparison/\" + loc + \"_similar.csv\", index=False)\n",
        "        \n",
        "\n",
        "        for allele in newPredict.keys():\n",
        "            allDict = {}\n",
        "            allDict[\"Allele\"] = allele\n",
        "            allDict[\"Serologic Assignment\"] = newPredict[allele]\n",
        "            if allele not in oldPredict.keys():\n",
        "                newDict[allele] = allDict\n",
        "        newFrame = pd.DataFrame.from_dict(simDict)\n",
        "        newFrame = newFrame.transpose()\n",
        "        newFrame.to_csv(base_dir + \"comparison/\" + loc + \"_newsies.csv\", index=False)\n",
        "\n",
        "        simLen = len(simFrame)\n",
        "        diffLen = len(diffFrame)\n",
        "        with open(base_dir + \"comparison/\" + loc + \"_concordance.txt\", \"w+\") as fhandle:\n",
        "            fhandle.write(\"HLA-\" +loc+ \" Similar: \" + str(simLen))\n",
        "            fhandle.write(\"HLA-\" +loc+ \" Different: \" + str(diffLen))\n",
        "            concordance = (simLen / (simLen + diffLen)) * 100\n",
        "            concordances[loc] = concordance\n",
        "            fhandle.write(\"HLA-\" +loc+ \" Concordance: \" + str(concordance) + \"%\")\n",
        "            if print_all == \"yes\":\n",
        "                print(\"HLA-\" +loc+ \" Similar: \" + str(simLen))\n",
        "                print(\"HLA-\" +loc+ \" Different: \" + str(diffLen))\n",
        "                print(\"HLA-\" +loc+ \" Concordance: \" + str(concordance) + \"%\")\n",
        "    return concordances\n",
        "\n",
        "#main(print_all=\"yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueiWDlDFW84T"
      },
      "source": [
        "### Additional Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zvRk3CruIQdW"
      },
      "outputs": [],
      "source": [
        "# All data here from Sigma Aldrich\n",
        "# https://www.sigmaaldrich.com/life-science/metabolomics/learning-center/amino-acid-reference-chart.html\n",
        "\n",
        "mol_wghts = {\n",
        "    'A': 89.10,\n",
        "    'R': 174.20,\n",
        "    'N': 132.12,\n",
        "    'D': 133.11,\n",
        "    'C': 121.16,\n",
        "    'E': 147.13,\n",
        "    'Q': 146.15,\n",
        "    'G': 75.07,\n",
        "    'H': 155.16,\n",
        "    #'O': 131.13,\n",
        "    'I': 131.18,\n",
        "    'L': 131.18,\n",
        "    'K': 146.19,\n",
        "    'M': 149.21,\n",
        "    'F': 165.19,\n",
        "    'P': 115.13,\n",
        "    #'U': 139.11,\n",
        "    'S': 105.09,\n",
        "    'T': 119.12,\n",
        "    'W': 204.23,\n",
        "    'Y': 181.19,\n",
        "    'V': 117.15,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n",
        "\n",
        "pKa = {\n",
        "    'A': 2.34,\n",
        "    'R': 2.17,\n",
        "    'N': 2.02,\n",
        "    'D': 1.88,\n",
        "    'C': 1.96,\n",
        "    'E': 2.19,\n",
        "    'Q': 2.17,\n",
        "    'G': 2.34,\n",
        "    'H': 1.82,\n",
        "    #'O': 1.82,\n",
        "    'I': 2.36,\n",
        "    'L': 2.36,\n",
        "    'K': 2.18,\n",
        "    'M': 2.28,\n",
        "    'F': 1.83,\n",
        "    'P': 1.99,\n",
        "    #'U': 0,\n",
        "    'S': 2.21,\n",
        "    'T': 2.09,\n",
        "    'W': 2.83,\n",
        "    'Y': 2.20,\n",
        "    'V': 2.32,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n",
        "\n",
        "pKb = {\n",
        "    'A': 9.69,\n",
        "    'R': 9.04,\n",
        "    'N': 8.80,\n",
        "    'D': 9.60,\n",
        "    'C': 10.28,\n",
        "    'E': 9.67,\n",
        "    'Q': 9.13,\n",
        "    'G': 9.60,\n",
        "    'H': 9.17,\n",
        "    #'O': 9.65,\n",
        "    'I': 9.60,\n",
        "    'L': 9.60,\n",
        "    'K': 8.95,\n",
        "    'M': 9.21,\n",
        "    'F': 9.13,\n",
        "    'P': 10.60,\n",
        "    #'U': 0,\n",
        "    'S': 9.15,\n",
        "    'T': 9.10,\n",
        "    'W': 9.39,\n",
        "    'Y': 9.11,\n",
        "    'V': 9.62,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n",
        "\n",
        "pKx = {\n",
        "    'A': 0,\n",
        "    'R': 12.48,\n",
        "    'N': 0,\n",
        "    'D': 3.65,\n",
        "    'C': 8.18,\n",
        "    'E': 4.25,\n",
        "    'Q': 0,\n",
        "    'G': 0,\n",
        "    'H': 6.00,\n",
        "    #'O': 0,\n",
        "    'I': 0,\n",
        "    'L': 0,\n",
        "    'K': 10.53,\n",
        "    'M': 0,\n",
        "    'F': 0,\n",
        "    'P': 0,\n",
        "    #'U': 0,\n",
        "    'S': 0,\n",
        "    'T': 0,\n",
        "    'W': 0,\n",
        "    'Y': 10.07,\n",
        "    'V': 0,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n",
        "\n",
        "pI = {\n",
        "    'A': 6.00,\n",
        "    'R': 10.76,\n",
        "    'N': 5.41,\n",
        "    'D': 2.77,\n",
        "    'C': 5.07,\n",
        "    'E': 3.22,\n",
        "    'Q': 5.65,\n",
        "    'G': 5.97,\n",
        "    'H': 7.59,\n",
        "    #'O': 0,\n",
        "    'I': 6.02,\n",
        "    'L': 5.98,\n",
        "    'K': 9.74,\n",
        "    'M': 5.74,\n",
        "    'F': 5.48,\n",
        "    'P': 6.30,\n",
        "    #'U': 5.68,\n",
        "    'S': 5.68,\n",
        "    'T': 5.60,\n",
        "    'W': 5.89,\n",
        "    'Y': 5.66,\n",
        "    'V': 5.96,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n",
        "\n",
        "# Hydrophobicity Index at pH 2\n",
        "HI2 = {\n",
        "    'A': 47,\n",
        "    'R': -26,\n",
        "    'N': -18,\n",
        "    'D': -18,\n",
        "    'C': 52,\n",
        "    'E': 8,\n",
        "    'Q': -18,\n",
        "    'G': 0,\n",
        "    'H': -42,\n",
        "    #'O': 0,\n",
        "    'I': 100,\n",
        "    'L': 100,\n",
        "    'K': -37,\n",
        "    'M': 74,\n",
        "    'F': 92,\n",
        "    'P': -46,\n",
        "    #'U': 0,\n",
        "    'S': -7,\n",
        "    'T': 13,\n",
        "    'W': 84,\n",
        "    'Y': 49,\n",
        "    'V': 79,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n",
        "\n",
        "# Hydrophobicity index at pH 7\n",
        "HI7 = {\n",
        "    'A': 41,\n",
        "    'R': -14,\n",
        "    'N': -28,\n",
        "    'D': -55,\n",
        "    'C': 49,\n",
        "    'E': -31,\n",
        "    'Q': -10,\n",
        "    'G': 0,\n",
        "    'H': 8,\n",
        "    #'O': 0,\n",
        "    'I': 99,\n",
        "    'L': 97,\n",
        "    'K': -23,\n",
        "    'M': 74,\n",
        "    'F': 100,\n",
        "    'P': -46, # SA used pH 2\n",
        "    #'U': 0,\n",
        "    'S': -5,\n",
        "    'T': 13,\n",
        "    'W': 97,\n",
        "    'Y': 63,\n",
        "    'V': 76,\n",
        "    '-': 0,\n",
        "    'X': 0,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHfBpAisqYP8"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8X6XHjx8I_4_"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "def one_hot_decode(df):\n",
        "\tdf['serology']=''\n",
        "\n",
        "\tfor col in df.columns:\n",
        "\t\tdf.loc[df[col]==1,'serology'] = df['serology']+col+';'\n",
        "\n",
        "\treturn df\n",
        "\n",
        "def fix_data(uniques, data, loc, iset, ident):\n",
        "    sero = {}\n",
        "    for row in data.itertuples(name='Pandas'):\n",
        "        sero[row.allele] = str(row.serology)\n",
        "        #sero[row[1]] = str(row[-1])\n",
        "  \t\n",
        "    data = data.drop('serology', axis=1)\n",
        "  \n",
        "    for key in sero.keys():\n",
        "        '''\n",
        "    \t    # not applicable for old_sets train/test\n",
        "        if (sero[key].find(';') != -1):\n",
        "            sero[key] = sero[key].replace('a','')\n",
        "            sero[key] = sero[key].split(';')\n",
        "        else:\n",
        "            sero[key] = sero[key].replace('a','')\n",
        "            sero[key] = [sero[key]]\n",
        "        '''\n",
        "  \n",
        "        #for old_sets train/test\n",
        "        sero[key] = sero[key].split(' ')\n",
        "      \n",
        "        for x in sero[key]:\n",
        "            if (x not in uniques):\n",
        "                uniques.append(x)\n",
        "            else:\n",
        "                continue\n",
        "  \n",
        "    uniques = list(map(int, uniques))\n",
        "    uniques.sort()\n",
        "    uniques = list(map(str, uniques))\n",
        "    \n",
        "    for y in uniques:\n",
        "        data[y] = 0\n",
        "  \n",
        "    one_sero = {}\n",
        "    for key in sero.keys():\n",
        "        one_sero[key] = { some_key : (\"1\" if (some_key in sero[key]) else \"0\")\n",
        "  \t  \t                    for some_key in uniques }\n",
        "    one_df = pd.DataFrame.from_dict(one_sero)\n",
        "    one_df = one_df.transpose()\n",
        "    one_df.index.name = \"allele\"\n",
        "    data = data.set_index('allele')\n",
        "    data.update(one_df, overwrite=True)\n",
        "    data.to_csv(base_dir + 'randfor/'+iset+'/'+loc+'_'+ident+'.csv', index=True)\n",
        "    return data, uniques\n",
        "\n",
        "\n",
        "def add_data(df):\n",
        "    OHcols = list(df.columns)\n",
        "    OHcols.remove('serology')\n",
        "    OHcols.remove('allele')\n",
        "\n",
        "    for col in OHcols:\n",
        "        MWname = 'MW'+str(col)\n",
        "        df[MWname] = df.apply(lambda row: mol_wghts[row[col]], axis=1)\n",
        "        pKaname = 'pKa'+str(col)\n",
        "        df[pKaname] = df.apply(lambda row: pKa[row[col]], axis=1)\n",
        "        pKbname = 'pKb'+str(col)\n",
        "        df[pKbname] = df.apply(lambda row: pKb[row[col]], axis=1)\n",
        "        pKxname = 'pKx'+str(col)\n",
        "        df[pKxname] = df.apply(lambda row: pKx[row[col]], axis=1)\n",
        "        pIname = 'pI'+str(col)\n",
        "        df[pIname] = df.apply(lambda row: pI[row[col]], axis=1)\n",
        "        HI2name = 'HI2_'+str(col)\n",
        "        df[HI2name] = df.apply(lambda row: HI2[row[col]], axis=1)\n",
        "        HI7name = 'HI7_'+str(col)\n",
        "        df[HI7name] = df.apply(lambda row: HI7[row[col]], axis=1)\n",
        "\n",
        "\n",
        "    \n",
        "    df = df.drop(columns=OHcols, axis=1)\n",
        "    df = df.drop('serology', axis=1)\n",
        "\n",
        "    return df\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nRENMRUnSxU"
      },
      "source": [
        "### Current Best Parameters for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hOB7BnQWRAgK"
      },
      "outputs": [],
      "source": [
        "\n",
        "RSEED = 0\n",
        "\n",
        "pre_concord = metrics()\n",
        "\n",
        "loci = [\"A\", \"B\", \"C\", \"DQB1\", \"DRB1\"]\n",
        "#loci = ['DQB1']\n",
        "nest = {\n",
        "    'A': 40, #10\n",
        "    'B': 25, #199\n",
        "    'C': 5, #14\n",
        "    'DQB1': 64, #10\n",
        "    'DRB1': 16 #250\n",
        "}\n",
        "\n",
        "modfeat = {\n",
        "    'A':  'auto', #auto\n",
        "    'B': 1, #auto\n",
        "    'C': 'log2', #log2\n",
        "    'DQB1': 1, #log2\n",
        "    'DRB1': 'log2' #log2\n",
        "}\n",
        "\n",
        "\n",
        "numfeat = {\n",
        "    'A':  100, #False\n",
        "    'B': 200, #False\n",
        "    'C': 200, #False\n",
        "    'DQB1': 100, #False\n",
        "    'DRB1': False #log2\n",
        "}\n",
        "\n",
        "boot = {\n",
        "    'A': False,\n",
        "    'B': False,\n",
        "    'C': False,\n",
        "    'DQB1': False,\n",
        "    'DRB1': False\n",
        "}\n",
        "\n",
        "#boot = {\n",
        "#    'A': True,\n",
        "#    'B': True,\n",
        "#    'C': True,\n",
        "#    'DQB1': True,\n",
        "#    'DRB1': True\n",
        "#}\n",
        "\n",
        "criteria = {\n",
        "    'A': 'gini',\n",
        "    'B': 'gini',\n",
        "    'C': 'gini',\n",
        "    'DQB1': 'gini',\n",
        "    'DRB1': 'gini'\n",
        "}\n",
        "\n",
        "oob = {\n",
        "    'A': False,\n",
        "    'B': False,\n",
        "    'C': False,\n",
        "    'DQB1': False,\n",
        "    'DRB1': False\n",
        "}\n",
        "\n",
        "#oob = {\n",
        "#    'A': True,\n",
        "#    'B': True,\n",
        "#    'C': True,\n",
        "#    'DQB1': True,\n",
        "#    'DRB1': True\n",
        "#}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3qeTvY_nJv9"
      },
      "source": [
        "### Random Forest Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce001623c7504098ac23de019b0781d2",
            "1165788a06454a3e8aaf701b036c082e",
            "75dcc6134af644c88a4fcfb2fc937717",
            "83272967180c4ece8636a2d6bbdb1277",
            "bd75460274d64fb696529d6bfe59cebd",
            "6cb757ca9eb347d79b9367ac54ae2788",
            "cb6bcfb69dd5474e970ffa4951548279",
            "e6b4ce5ccc82490ea88e279a1708c0fb",
            "16c61bd0779044e28edbf2243c8c45e5",
            "57cf106b7f4d4082a9e1ad04691657ef",
            "978018f7713b4b818160950f0cb193d5"
          ]
        },
        "id": "gMuQNEezJCnX",
        "outputId": "0d4fe592-c43e-4ce1-e934-8bd3cf88da0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e82928159c474c88383cd1ffa79601",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A...B...C...DQB1...DRB1...Done.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "RSEED = 0\n",
        "\n",
        "pre_concord = metrics()\n",
        "\n",
        "print(\"Predicting...\")\n",
        "for loc in tqdm(loci):\n",
        "    uniques = []\n",
        "    print(loc+'...', end='')\n",
        "    features = pd.read_csv(base_dir + \"OHtraining/\" + loc + \"_train.csv\")\n",
        "    vfeatures = pd.read_csv(base_dir + \"OHtraining/\" + loc + \"_validation.csv\")\n",
        "    test = pd.read_csv(base_dir + \"OHtesting/\" + loc + \"_test.csv\")\n",
        "    features, sers = fix_data(uniques, features,loc,iset='training',ident='train')\n",
        "    vfeatures, vsers = fix_data(uniques, vfeatures,loc,iset='training',ident='validation')\n",
        "\n",
        "    test = test.drop('serology', axis=1)\n",
        "    test.to_csv(base_dir + 'randfor/testing/'+loc+'_test.csv', index=True)\n",
        "\n",
        "  \n",
        "    features = features.append(vfeatures)\n",
        "    # had to change following two lines from sers to vsers to account for additional validation data\n",
        "    labels = np.array(features[vsers])\n",
        "    features = features.drop(vsers, axis=1)\n",
        "    features = features.reset_index()\n",
        "    indices = features[\"allele\"]\n",
        "    indices = list(indices)\n",
        "    features = features.drop('allele', axis=1)\n",
        "    feature_list = list(features.columns)\n",
        "    n_features = len(feature_list)\n",
        "    #maxfeat = int(math.sqrt(n_features))\n",
        "  \n",
        "    all_features = features\n",
        "    features = np.array(features)\n",
        "    labels[labels!=labels]='0'\n",
        "    features[features!=features]='0'\n",
        "    features = features.astype(int)\n",
        "    labels = labels.astype(int)\n",
        "  \n",
        "    test_idcs = test['allele']\n",
        "    test = test.drop('allele', axis=1)\n",
        "    #print(test.head(100))\n",
        "    all_test = test\n",
        "    test_list = list(test.columns)\n",
        "    test = np.array(test)\n",
        "    test[test!=test]='0'\n",
        "    test = test.astype(int)\n",
        "    ind_labels = [str(x) for x in sers]\n",
        "\n",
        "\n",
        "    all_predictions = []\n",
        "    for idx in range(0,len(ind_labels)):\n",
        "        ilabels = labels[:,idx]\n",
        "        forest = RandomForestClassifier(n_estimators=nest[loc],\n",
        "                                        criterion=criteria[loc], \n",
        "                                        bootstrap=boot[loc],\n",
        "                                        oob_score=oob[loc],\n",
        "                                        max_features=modfeat[loc],\n",
        "                                        random_state=RSEED, \n",
        "                                        n_jobs=-1)\n",
        "        forest.fit(features,ilabels)\n",
        "        #predictions = forest.predict(test)\n",
        "        threshold = 0.42\n",
        "\n",
        "        #predictions = forest.predict_proba(test)\n",
        "        #predictions[:,0] = (predictions[:,0] < threshold).astype('int')\n",
        "        #predictions = (predictions[:,1] >= threshold).astype('int')\n",
        "        #all_predictions.append(predictions)\n",
        "\n",
        "\n",
        "        # Feature/Permutation Importance\n",
        "        #feat_indices = np.argsort(forest.feature_importances_)[::-1]\n",
        "        if numfeat[loc] != False:\n",
        "            tree_importance_sorted_idx = np.argsort(forest.feature_importances_)\n",
        "            tree_importance_sorted_idx = tree_importance_sorted_idx[-numfeat[loc]:]\n",
        "            less_features = np.array(feature_list)[tree_importance_sorted_idx]\n",
        "            new_features = all_features[less_features]\n",
        "            new_features = np.array(new_features)\n",
        "            new_features[new_features!=new_features]='0'\n",
        "            new_features = new_features.astype(int)\n",
        "            less_test = np.array(test_list)[tree_importance_sorted_idx]\n",
        "            new_test = all_test[less_test]        \n",
        "            new_test = np.array(new_test)\n",
        "            new_test[new_test!=new_test]='0'\n",
        "            new_test = new_test.astype(int)\n",
        "            new_forest = RandomForestClassifier(n_estimators=nest[loc],\n",
        "                                            criterion=criteria[loc], \n",
        "                                            bootstrap=boot[loc],\n",
        "                                            oob_score=oob[loc],\n",
        "                                            max_features=modfeat[loc],\n",
        "                                            random_state=RSEED, \n",
        "                                            n_jobs=-1)\n",
        "            new_forest.fit(new_features,ilabels)\n",
        "            #threshold = 0.42\n",
        "\n",
        "            predictions = new_forest.predict_proba(new_test)\n",
        "            predictions[:,0] = (predictions[:,0] < threshold).astype('int')\n",
        "            predictions = (predictions[:,1] >= threshold).astype('int')\n",
        "            all_predictions.append(predictions)\n",
        "        else:\n",
        "            predictions = forest.predict_proba(test)\n",
        "            predictions[:,0] = (predictions[:,0] < threshold).astype('int')\n",
        "            predictions = (predictions[:,1] >= threshold).astype('int')\n",
        "            all_predictions.append(predictions)\n",
        "\n",
        "        '''\n",
        "        result = permutation_importance(forest, features, ilabels, n_repeats=10, random_state=RSEED, n_jobs=-1)\n",
        "        perm_sorted_idx = result.importances_mean.argsort()\n",
        "        perm_sorted_idx = perm_sorted_idx[-50:]\n",
        "\n",
        "        \n",
        "        with open(base_dir+'perm_importance/'+loc+'-'+ind_labels[idx]+'_rank.txt', 'w+') as handle:\n",
        "            # Print the feature ranking\n",
        "            handle.write(\"Feature ranking: \\n\")\n",
        "            for x in range(features.shape[1]):\n",
        "                handle.write(\"{}. feature {} ({})\\n\".format(str(x + 1), str(feature_list[feat_indices[x]]), str(importances[feat_indices[x]])))\n",
        "        \n",
        "\n",
        "        tree_importance_sorted_idx = np.argsort(forest.feature_importances_)\n",
        "        tree_importance_sorted_idx = tree_importance_sorted_idx[-50:]\n",
        "        tree_indices = np.arange(0, len(tree_importance_sorted_idx)) + 0.5\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
        "        ax1.barh(tree_indices,\n",
        "                forest.feature_importances_[tree_importance_sorted_idx]) #, height=0.7)\n",
        "        ax1.set_yticks(tree_indices)\n",
        "        ax1.set_yticklabels(np.array(feature_list)[tree_importance_sorted_idx])\n",
        "        #ax1.set_ylim((0, len(forest.feature_importances_)))\n",
        "        ax1.set_ylim((0, 50))\n",
        "        ax2.boxplot(\n",
        "            result.importances[perm_sorted_idx].T, \n",
        "            vert=False,\n",
        "            labels=np.array(feature_list)[perm_sorted_idx])\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(base_dir+'perm_importance/'+loc+'-'+ind_labels[idx]+\".pdf\", bbox_inches='tight')\n",
        "        #plt.show()'\n",
        "\n",
        "        # Multicollinearity\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
        "        corr = spearmanr(features[:50]).correlation\n",
        "        print(corr)\n",
        "\n",
        "        # Ensure the correlation matrix is symmetric\n",
        "        corr = (corr + corr.T) / 2\n",
        "        np.fill_diagonal(corr, 1)\n",
        "\n",
        "        # We convert the correlation matrix to a distance matrix before performing\n",
        "        # hierarchical clustering using Ward's linkage.\n",
        "        distance_matrix = 1 - np.abs(corr)\n",
        "        dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
        "        dendro = hierarchy.dendrogram(\n",
        "            dist_linkage, labels=feature_list, ax=ax1, leaf_rotation=90\n",
        "        )\n",
        "        dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
        "\n",
        "        ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
        "        ax2.set_xticks(dendro_idx)\n",
        "        ax2.set_yticks(dendro_idx)\n",
        "        ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
        "        ax2.set_yticklabels(dendro[\"ivl\"])\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(base_dir+'perm_importance/'+loc+'-'+ind_labels[idx]+\"-dendro.pdf\", bbox_inches='tight')\n",
        "        #plt.show()\n",
        "\n",
        "        cluster_ids = hierarchy.fcluster(dist_linkage, 1, criterion=\"distance\")\n",
        "        cluster_id_to_feature_ids = defaultdict(list)\n",
        "        for idx, cluster_id in enumerate(cluster_ids):\n",
        "            cluster_id_to_feature_ids[cluster_id].append(idx)\n",
        "        selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
        "\n",
        "        X_train_sel = X_train[:, selected_features]\n",
        "        X_test_sel = X_test[:, selected_features]\n",
        "\n",
        "        clf_sel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        clf_sel.fit(X_train_sel, y_train)\n",
        "        print(\n",
        "            \"Accuracy on test data with features removed: {:.2f}\".format(\n",
        "                clf_sel.score(X_test_sel, y_test)\n",
        "            )\n",
        "        )\n",
        "        '''\n",
        "\n",
        "    all_predictions = np.asarray(all_predictions)\n",
        "    all_predictions = np.transpose(all_predictions)\n",
        "\n",
        "    explainer = lime.lime_tabular.LimeTabularExplainer(features,feature_names=feature_list,class_names=ind_labels,kernel_width=5)\n",
        "    for rowexp in range(0,1):\n",
        "      exp = explainer.explain_instance(test[rowexp], forest.predict_proba, num_features=n_features)\n",
        "      exp.save_to_file('{}_{}.lime.html'.format(loc, str(rowexp)), show_table=True)\n",
        "  \n",
        "    #preds_output = pd.DataFrame(predictions, index=test_idcs, columns=ind_labels)\n",
        "    preds_output = pd.DataFrame(all_predictions, index=test_idcs, columns=ind_labels)\n",
        "    preds_output = one_hot_decode(preds_output)\n",
        "    preds_output = preds_output.drop(ind_labels, axis=1)\n",
        "    preds_output.index.name = 'allele'\n",
        "    preds_output = preds_output.apply(lambda x: str((x['serology'].split(';'))[:-1]), result_type='broadcast', axis=1)\n",
        "    preds_output.to_csv(base_dir + 'predictions/'+loc+'_predictions.csv', index=True)\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KOHE0OvnObO"
      },
      "source": [
        "### Concordance Checker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HP2SpEXdJFEy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A Concordance:\t\t\t\t96.67%\n",
            "% Change:\t\t\t\t0.0%\n",
            "B Concordance:\t\t\t\t88.50%\n",
            "% Change:\t\t\t\t-1.60%\n",
            "C Concordance:\t\t\t\t93.65%\n",
            "% Change:\t\t\t\t-3.66%\n",
            "DQB1 Concordance:\t\t\t\t93.15%\n",
            "% Change:\t\t\t\t0.0%\n",
            "DRB1 Concordance:\t\t\t\t88.03%\n",
            "% Change:\t\t\t\t0.0%\n"
          ]
        }
      ],
      "source": [
        "post_concord = metrics()\n",
        "\n",
        "for loc in loci:\n",
        "\tprint(loc + \" Concordance:\\t\\t\\t\\t\" + str(post_concord[loc])[:5] + \"%\")\n",
        "\tchange = post_concord[loc] - pre_concord[loc]\n",
        "\tprint(\"% Change:\\t\\t\\t\\t\" + str(change)[:5] + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "943nxLa5nBoG"
      },
      "source": [
        "### Accuracy Checker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-ZxoNKm4rOxI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest:\n",
            "                                   A          B          C  DQB1       DRB1\n",
            "All Calls Correct          70.707071  78.205128  85.714286  80.0  60.000000\n",
            "Incorrect                  29.292929  21.794872  14.285714  20.0  40.000000\n",
            "At Least One Correct Call  22.222222   9.615385  14.285714  20.0  25.714286\n",
            "All Calls Incorrect         7.070707  12.179487   0.000000   0.0  14.285714\n",
            "\n",
            "\n",
            "RSNNS:\n",
            "                                   A          B          C       DQB1       DRB1\n",
            "All Calls Correct          68.686869  76.282051  78.571429  73.333333  57.142857\n",
            "Incorrect                  31.313131  23.717949  21.428571  26.666667  42.857143\n",
            "At Least One Correct Call  24.242424  12.820513  19.047619  20.000000  25.714286\n",
            "All Calls Incorrect         7.070707  10.897436   2.380952   6.666667  17.142857\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "loci = ['A', 'B', 'C', 'DQB1', 'DRB1']\n",
        "summary = {}\n",
        "\n",
        "# dict of dicts to store splits of broad specificities\n",
        "broad_split = {\n",
        "    \"A\" : {\n",
        "        \"9\" : [\"23\", \"24\"],\n",
        "        \"10\" : [\"25\", \"26\", \"34\", \"66\"],\n",
        "        \"19\" : [\"29\", \"30\", \"31\", \"32\", \"33\", \"74\"],\n",
        "        \"28\" : [\"68\", \"69\"]\n",
        "    },\n",
        "    \"B\" : {\n",
        "        \"5\" : [\"51\", \"52\"],\n",
        "        \"12\" : [\"44\", \"45\"],\n",
        "        \"14\" : [\"64\", \"65\"],\n",
        "        \"15\" : [\"62\", \"63\", \"75\", \"76\", \"77\"],\n",
        "        \"16\" : [\"38\", \"39\"],\n",
        "        \"17\" : [\"57\", \"58\"],\n",
        "        \"21\" : [\"49\", \"50\"],\n",
        "        \"22\" : [\"54\", \"55\", \"56\"],\n",
        "        \"40\" : [\"60\", \"61\"],\n",
        "        \"70\" : [\"71\", \"72\"]\n",
        "    },\n",
        "    \"C\" : {\n",
        "        \"3\" : [\"9\", \"10\"]\n",
        "    },\n",
        "    \"DQB1\" : {\n",
        "        \"1\" : [\"5\", \"6\"],\n",
        "        \"3\" : [\"7\", \"8\", \"9\"]\n",
        "    },\n",
        "    \"DRB1\" : {\n",
        "        \"2\" : [\"15\", \"16\"],\n",
        "        \"3\" : [\"17\", \"18\"],\n",
        "        \"5\" : [\"11\", \"12\"],\n",
        "        \"6\" : [\"13\", \"14\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# dict of dict to store broad specificity for each split\n",
        "split_broad = {}\n",
        "\n",
        "for alphakey in broad_split.keys():\n",
        "    sb = {}\n",
        "    \n",
        "    for betakey in broad_split[alphakey].keys():\n",
        "        for value in broad_split[alphakey][betakey]:\n",
        "            sb[value] = betakey\n",
        "    \n",
        "    split_broad[alphakey] = sb\n",
        "\n",
        "# function to check if value can be an integer - to eliminate excess characters from serology labels\n",
        "def checkInt(x):\n",
        "    try:\n",
        "        int(x)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "# function to eliminate any serological assignments with under a 95% likelihood\n",
        "def chance(x, line):\n",
        "    if (line[x].find(\"%\") != -1):\n",
        "        x = float(line[x][:-1])\n",
        "        if 51 <= x:\n",
        "            test = True\n",
        "        else:\n",
        "            test = False\n",
        "    else:\n",
        "        test = False\n",
        "    return test\n",
        "\n",
        "# function to generate dataframes to contain SNNS predictions\n",
        "def SNNS_preds(loci=loci):\n",
        "    for loc in loci:\n",
        "        oldPredict = {}\n",
        "        oldPredFile = NN_dir + \"old-predictions/\" + loc + \".chile\"\n",
        "        with open(oldPredFile, \"r\") as handle:\n",
        "            for line in handle:\n",
        "                if line.find('%') != -1:\n",
        "                    line = line.split()\n",
        "                    if line != []:\n",
        "                        line[:] = [x for x in line if x != '[100.00%]']\n",
        "                        allele = loc + \"*\" + str(line[0][:-1])\n",
        "                        oldPredict[allele] = ' '.join(line[1:])\n",
        "                else:\n",
        "                    next\n",
        "\n",
        "        opseries = pd.Series(oldPredict, name=\"serology\")\n",
        "        opseries.index.name = \"allele\"\n",
        "        opseries.reset_index()\n",
        "        opseries.to_csv(NN_dir+\"old-predictions/\"+loc+\"_predictions.csv\", line_terminator='\\n')\n",
        "    return\n",
        "\n",
        "# function to measure concordance between old SNNS and new ML models\n",
        "def concordance(loci=loci):\n",
        "    for loc in loci:\n",
        "        comparison = open(NN_dir+\"comparison/\" + loc + \"_compfile.txt\", \"w+\")\n",
        "        newsies = open(NN_dir+\"comparison/\" + loc + \"_newsies.txt\", \"w+\")\n",
        "        similarities = open(NN_dir+\"comparison/\" + loc + \"_similar.txt\", \"w+\")\n",
        "        oldPredict = {}\n",
        "        newPredict = {}\n",
        "        oldPredFile = NN_dir+\"old-predictions/\" + loc + \".chile\"\n",
        "        newPreds = pd.read_csv(NN_dir+\"predictions/\" + loc + \"_predictions.csv\")\n",
        "        newPreds = newPreds.set_index('allele')\n",
        "        newPreds = newPreds.to_dict()\n",
        "        newPredict = newPreds[\"serology\"]\n",
        "        for nKey in newPredict.keys():\n",
        "            adjustMe = str(newPredict[nKey])\n",
        "            adjustMe = adjustMe.replace('[','')\n",
        "            adjustMe = adjustMe.replace(']','')\n",
        "            adjustMe = adjustMe.replace('a','')\n",
        "            adjustMe = adjustMe.replace(\"'\",'')\n",
        "            adjustMe = adjustMe.split(' ')\n",
        "            newPredict[nKey] = [x.strip('a') for x in adjustMe if checkInt(x)]\n",
        "        with open(oldPredFile, \"r\") as handle:\n",
        "            for line in handle:\n",
        "                if line.find('%') == -1:\n",
        "                    next\n",
        "                else:\n",
        "                    line = handle.readline()\n",
        "                    line = line.split()\n",
        "                    if line == []:\n",
        "                        next\n",
        "                    else:\n",
        "                        line[:] = [x for x in line if x != '[100.00%]']\n",
        "                        allele = loc + \"*\" + str(line[0][:-1])\n",
        "                        oldPredict[allele] = line[1:]\n",
        "\n",
        "        for each in oldPredict.keys():\n",
        "            if each not in newPredict.keys():\n",
        "                next\n",
        "            elif set(newPredict[each]) != set(oldPredict[each]):\n",
        "                comparison.write(\"Different: \" + str(each) + \"\\n\")\n",
        "                comparison.write(\"Old Serologic Assignment: \" + str(oldPredict[each]) + \"\\n\")\n",
        "                comparison.write(\"New Serologic Assignment: \" + str(newPredict[each]) + \"\\n\")\n",
        "            elif set(newPredict[each]) == set(oldPredict[each]):\n",
        "                similarities.write(\"Same: \" + str(each) + \"\\n\")\n",
        "                similarities.write(\"Old Serologic Assignment: \" + str(oldPredict[each]) + \"\\n\")\n",
        "                similarities.write(\"New Serologic Assignment: \" + str(newPredict[each]) + \"\\n\")\n",
        "        comparison.close()\n",
        "        similarities.close()\n",
        "\n",
        "        for allele in newPredict.keys():\n",
        "            if allele not in oldPredict.keys():\n",
        "                newsies.write(\"NEW: \" + str(allele) + \"\\n\")\n",
        "                newsies.write(\"Serologic Assignment: \" + str(newPredict[allele]) + \"\\n\")\n",
        "        newsies.close()\n",
        "    \n",
        "    return\n",
        " \n",
        "def summary_table(loci=loci, summary=summary):\n",
        "    for locus in loci:\n",
        "        summary_data = {}\n",
        "        trn_set = pd.read_csv('training/' + locus + '_train.csv')\n",
        "        val_set = pd.read_csv('training/' + locus + '_validation.csv')\n",
        "        tst_set = pd.read_csv('testing/' + locus + '_test.csv')\n",
        "\n",
        "        old_trn_set = pd.read_csv('old_sets/train/' + locus + '_train.csv')\n",
        "        old_val_set = pd.read_csv('old_sets/train/' + locus + '_validation.csv')\n",
        "        old_tst_set = pd.read_csv('old_sets/test/' + locus + '_test.csv')\n",
        "\n",
        "        trnlen = float(len(trn_set))\n",
        "        vallen = float(len(val_set))\n",
        "        tstlen = float(len(tst_set))\n",
        "        polyAA = float(len(trn_set.iloc[0])) - 1\n",
        "        oldtrnlen = float(len(old_trn_set))\n",
        "        oldvallen = float(len(old_val_set))\n",
        "        oldtstlen = float(len(old_tst_set))\n",
        "        oldpolyAA = float(len(old_trn_set.iloc[0])) - 1\n",
        "\n",
        "        summary_data['Number of Training Alleles'] = trnlen\n",
        "        summary_data['R-SNNS Number of Training Alleles'] = oldtrnlen\n",
        "        summary_data['Difference in Training Set'] = trnlen - oldtrnlen\n",
        "        summary_data['Percent (%) Growth in Training Set'] = ((trnlen - oldtrnlen)/oldtrnlen) * 100\n",
        "        summary_data['Number of Validation Alleles'] = vallen\n",
        "        summary_data['R-SNNS Number of Validation Alleles'] = oldvallen\n",
        "        summary_data['Difference in Validation Set'] = vallen - oldvallen\n",
        "        summary_data['Percent (%) Growth in Validation Set'] = ((vallen - oldvallen)/oldvallen) * 100\n",
        "        summary_data['Number of Testing Alleles'] = tstlen\n",
        "        summary_data['R-SNNS Number of Testing Alleles'] = oldtstlen\n",
        "        summary_data['Difference in Testing Set'] = tstlen - oldtstlen\n",
        "        summary_data['Percent (%) Growth in Testing Set'] = ((tstlen - oldtstlen)/oldtstlen) * 100\n",
        "        summary_data['Number of Polymorphisms'] = polyAA\n",
        "        summary_data['R-SNNS Number of Polymorphisms'] = oldpolyAA\n",
        "        summary_data['Difference in Polymorphisms'] = polyAA - oldpolyAA\n",
        "        summary_data['Percent (%) Growth in Polymorphisms'] = ((polyAA - oldpolyAA)/oldpolyAA) * 100\n",
        "        summary[locus] = summary_data\n",
        "        \n",
        "    sum_df = pd.DataFrame(data=summary)\n",
        "\n",
        "    sum_df.to_csv(NN_dir+'comparison/summary.csv', index=True)\n",
        "    \n",
        "    return\n",
        "\n",
        "def evaluate(loc, p_allele, relser, right, wrong, partial, bad, broad_split=broad_split, split_broad=split_broad):\n",
        "    p_ser = str(p_allele.serology).replace(\"'\",'').replace('[','').replace(']','').replace('\"','').replace(',','')\n",
        "    p_ser = set(p_ser.split(' '))\n",
        "    \n",
        "    if p_allele.allele in relser.index:\n",
        "        newser = set(relser.loc[p_allele.allele].serology.split(' '))\n",
        "        if p_ser == newser:\n",
        "            right.append(p_allele.allele)\n",
        "        elif p_ser != newser:\n",
        "            wrong.append(p_allele.allele)\n",
        "            if any([w in newser for w in p_ser]):\n",
        "                partial.append(p_allele.allele)\n",
        "            else:\n",
        "                bad.append(p_allele.allele)\n",
        "\n",
        "        return right, wrong, partial, bad\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        return right, wrong, partial, bad\n",
        "\n",
        "def met_pct(datalist, right, wrong, partial, bad):\n",
        "    n_alleles = len(datalist)\n",
        "    #print(n_alleles)\n",
        "    n_r = len(right)\n",
        "    n_w = len(wrong)\n",
        "    n_p = len(partial)\n",
        "    n_b = len(bad)\n",
        "\n",
        "    p_r = (n_r / n_alleles) * 100\n",
        "    p_w = (n_w / n_alleles) * 100\n",
        "    p_p = (n_p / n_alleles) * 100\n",
        "    p_b = (n_b / n_alleles) * 100\n",
        "\n",
        "    p_dict = {\n",
        "        \"All Calls Correct\" : p_r,\n",
        "        \"Incorrect\" : p_w,\n",
        "        \"At Least One Correct Call\" : p_p,\n",
        "        \"All Calls Incorrect\" : p_b,\n",
        "    }\n",
        "\n",
        "    return p_dict\n",
        "\n",
        "def accuracy(loc, dataframe, relser):\n",
        "    right = []\n",
        "    wrong = []\n",
        "    partial = []\n",
        "    bad = []\n",
        "\n",
        "    #print(loc)\n",
        "\n",
        "    for all in dataframe.iloc:\n",
        "        # FIXME - A*23:19Q does not appear in rel_dna_ser (A*23:19N instead)\n",
        "        # FIXME - B*07:44 does not appear in rel_dna_ser (B*07:44N instead)\n",
        "        # FIXME - B*08:06 does not appear in rel_dna_ser at all\n",
        "        # FIXME - B*49:15 does not appear in rel_dna_ser at all\n",
        "        # FIXME - C*03:23 does not appear in rel_dna_ser (C*03:23N instead)\n",
        "        # FIXME - C*03:99 does not appear in rel_dna_ser at all\n",
        "        # FIXME - C*05:02 does not appear in rel_dna_ser at all\n",
        "        # FIXME - C*07:226 does not appear in rel_dna_ser (C*07:226Q instead)\n",
        "        if all.allele in [\"A*23:19Q\", \"B*07:44\", \"B*08:06\", \"B*49:15\", \"C*03:23\", \"C*03:99\", \"C*05:02\", \"C*07:226\"]:\n",
        "            continue\n",
        "        \n",
        "        right, wrong, partial, bad = evaluate(loc, all, relser, right, wrong, partial, bad)\n",
        "\n",
        "    df = relser[relser.index.isin(dataframe.allele)]\n",
        "\n",
        "    met_dict = met_pct(df, right, wrong, partial, bad)\n",
        "\n",
        "    return met_dict\n",
        "\n",
        "\n",
        "def check_acc_all(loci=loci):\n",
        "    mets = {\n",
        "        \"Old NN\" : {},\n",
        "        \"New NN\" : {},\n",
        "        \"Random Forest\" : {},\n",
        "    }\n",
        "\n",
        "    for loc in loci:    \n",
        "        old_nn_preds = pd.read_csv(NN_dir+\"old-predictions/\"+loc+\"_predictions.csv\", dtype=str)\n",
        "        new_nn_preds = pd.read_csv(NN_dir+\"predictions/\"+loc+\"_predictions.csv\", dtype=str)\n",
        "        new_nn_preds = new_nn_preds[new_nn_preds.allele.isin(old_nn_preds.allele)]\n",
        "        rf_preds = pd.read_csv(NN_dir+\"randomforest/predictions/\"+loc+\"_predictions.csv\", dtype=str)\n",
        "        rf_preds = rf_preds[rf_preds.allele.isin(old_nn_preds.allele)]\n",
        "        # added this filter to make sure all comparisons are identical\n",
        "        old_nn_preds = old_nn_preds[old_nn_preds.allele.isin(rf_preds.allele)]\n",
        "        #print('{}:\\t\\t{} alleles'.format(loc, str(len(old_nn_preds))))\n",
        "        relser = pd.read_csv(NN_dir+\"ser/\"+loc+\"_ser.csv\", dtype=str)\n",
        "        relser = relser.set_index('allele')\n",
        "        relser = relser.dropna()\n",
        "\n",
        "        mets[\"Old NN\"][loc] = accuracy(loc, old_nn_preds, relser)\n",
        "        mets[\"New NN\"][loc] = accuracy(loc, new_nn_preds, relser)\n",
        "        mets[\"Random Forest\"][loc] = accuracy(loc, rf_preds, relser)\n",
        "\n",
        "    return mets\n",
        "\n",
        "def compare_acc(mets, opt1, opt2, loci=loci):\n",
        "    c_dict = {}\n",
        "    for loc in loci:\n",
        "        l_dict = {}\n",
        "        r1 = mets[opt1][loc]['All Calls Correct']\n",
        "        w1 = mets[opt1][loc]['Incorrect']\n",
        "        p1 = mets[opt1][loc]['At Least One Correct Call']\n",
        "        b1 = mets[opt1][loc]['All Calls Incorrect']\n",
        "        r2 = mets[opt2][loc]['All Calls Correct']\n",
        "        w2 = mets[opt2][loc]['Incorrect']\n",
        "        p2 = mets[opt2][loc]['At Least One Correct Call']\n",
        "        b2 = mets[opt2][loc]['All Calls Incorrect']\n",
        "\n",
        "        l_dict['All Calls Correct'] = r2-r1\n",
        "        l_dict['Incorrect'] = w2-w1\n",
        "        l_dict['At Least One Correct Call'] = p2-p1\n",
        "        l_dict['All Calls Incorrect'] = b2-b1\n",
        "        c_dict[loc] = l_dict\n",
        "\n",
        "    return c_dict\n",
        "\n",
        "def compare_acc_all(mets):\n",
        "    cond1 = \"New_vs_Old_NN\"\n",
        "    cond2 = \"Random_Forest_vs_Old_NN\"\n",
        "    cond3 = \"Random_Forest_vs_New_NN\"\n",
        "\n",
        "    opt1 = \"Old NN\"\n",
        "    opt2 = \"New NN\"\n",
        "    opt3 = \"Random Forest\"\n",
        "\n",
        "    comp_dict = {\n",
        "        cond1 : {},\n",
        "        cond2 : {},\n",
        "        cond3 : {},\n",
        "    }\n",
        "\n",
        "    comp_dict[cond1] = compare_acc(mets, opt1, opt2)\n",
        "    cframe1 = pd.DataFrame.from_dict(comp_dict[cond1])\n",
        "    cframe1.to_csv(NN_dir+'comparison/'+cond1+'.csv', index=True)\n",
        "    comp_dict[cond2] = compare_acc(mets, opt1, opt3)\n",
        "    cframe2 = pd.DataFrame.from_dict(comp_dict[cond2])\n",
        "    cframe2.to_csv(NN_dir+'comparison/'+cond2+'.csv', index=True)\n",
        "    comp_dict[cond3] = compare_acc(mets, opt2, opt3)\n",
        "    cframe3 = pd.DataFrame.from_dict(comp_dict[cond3])\n",
        "    cframe3.to_csv(NN_dir+'comparison/'+cond3+'.csv', index=True)\n",
        "\n",
        "    return comp_dict\n",
        "\n",
        "concordance()\n",
        "mets = check_acc_all()\n",
        "mframe1 = pd.DataFrame.from_dict(mets['Old NN'])\n",
        "mframe1.to_csv(NN_dir+'comparison/OldNN_mets.csv', index=True)\n",
        "mframe2 = pd.DataFrame.from_dict(mets['New NN'])\n",
        "mframe2.to_csv(NN_dir+'comparison/NewNN_mets.csv', index=True)\n",
        "mframe3 = pd.DataFrame.from_dict(mets['Random Forest'])\n",
        "mframe3.to_csv(NN_dir+'comparison/RF_mets.csv', index=True)\n",
        "print(\"Random Forest:\")\n",
        "print(mframe3.to_string())\n",
        "print('\\n')\n",
        "print(\"RSNNS:\")\n",
        "print(mframe1.to_string())\n",
        "comp_dict = compare_acc_all(mets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY94z76xXhu_"
      },
      "source": [
        "## Automated Threshold Finder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7YrHNAGmxAI"
      },
      "source": [
        "### Contained Random Forest for Threshold Finder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aorQDVg-JJ1L"
      },
      "outputs": [],
      "source": [
        "RSEED = 0\n",
        "pre_concord = metrics()\n",
        "\n",
        "def predict_sero(loc, nest, boot, criteria, oob, modfeat, numfeat, threshold, i, prev_acc):\n",
        "    if i == 0:\n",
        "        prev_acc = pretest(loc)\n",
        "    uniques = []\n",
        "    features = pd.read_csv(base_dir + \"OHtraining/\" + loc + \"_train.csv\")\n",
        "    vfeatures = pd.read_csv(base_dir + \"OHtraining/\" + loc + \"_validation.csv\")\n",
        "    test = pd.read_csv(base_dir + \"OHtesting/\" + loc + \"_test.csv\")\n",
        "    features, sers = fix_data(uniques, features,loc,iset='training',ident='train')\n",
        "    vfeatures, vsers = fix_data(uniques, vfeatures,loc,iset='training',ident='validation')\n",
        "\n",
        "    test = test.drop('serology', axis=1)\n",
        "    test.to_csv(base_dir + 'randfor/testing/'+loc+'_test.csv', index=True)\n",
        "\n",
        "  \n",
        "    features = features.append(vfeatures)\n",
        "    # had to change following two lines from sers to vsers to account for additional validation data\n",
        "    labels = np.array(features[vsers])\n",
        "    features = features.drop(vsers, axis=1)\n",
        "    features = features.reset_index()\n",
        "    indices = features[\"allele\"]\n",
        "    indices = list(indices)\n",
        "    features = features.drop('allele', axis=1)\n",
        "    feature_list = list(features.columns)\n",
        "    n_features = len(feature_list)\n",
        "    #maxfeat = int(math.sqrt(n_features))\n",
        "  \n",
        "    all_features = features\n",
        "    features = np.array(features)\n",
        "    labels[labels!=labels]='0'\n",
        "    features[features!=features]='0'\n",
        "    features = features.astype(int)\n",
        "    labels = labels.astype(int)\n",
        "  \n",
        "    test_idcs = test['allele']\n",
        "    test = test.drop('allele', axis=1)\n",
        "    #print(test.head(100))\n",
        "    all_test = test\n",
        "    test_list = list(test.columns)\n",
        "    test = np.array(test)\n",
        "    test[test!=test]='0'\n",
        "    test = test.astype(int)\n",
        "    ind_labels = [str(x) for x in sers]\n",
        "\n",
        "    all_predictions = []\n",
        "    for idx in range(0,len(ind_labels)):\n",
        "        ilabels = labels[:,idx]\n",
        "        forest = RandomForestClassifier(n_estimators=nest,\n",
        "                                        criterion=criteria, \n",
        "                                        bootstrap=boot,\n",
        "                                        oob_score=oob,\n",
        "                                        max_features=modfeat,\n",
        "                                        random_state=RSEED, \n",
        "                                        n_jobs=-1)\n",
        "        forest.fit(features,ilabels)\n",
        "        #predictions = forest.predict(test)\n",
        "        #threshold = 0.42\n",
        "\n",
        "        #predictions = forest.predict_proba(test)\n",
        "        #predictions[:,0] = (predictions[:,0] < threshold).astype('int')\n",
        "        #predictions = (predictions[:,1] >= threshold).astype('int')\n",
        "        #all_predictions.append(predictions)\n",
        "\n",
        "\n",
        "        # Feature/Permutation Importance\n",
        "        #feat_indices = np.argsort(forest.feature_importances_)[::-1]\n",
        "        tree_importance_sorted_idx = np.argsort(forest.feature_importances_)\n",
        "        tree_importance_sorted_idx = tree_importance_sorted_idx[-numfeat:]\n",
        "\n",
        "        less_features = np.array(feature_list)[tree_importance_sorted_idx]\n",
        "        new_features = all_features[less_features]\n",
        "        new_features = np.array(new_features)\n",
        "        new_features[new_features!=new_features]='0'\n",
        "        new_features = new_features.astype(int)\n",
        "        less_test = np.array(test_list)[tree_importance_sorted_idx]\n",
        "        new_test = all_test[less_test]        \n",
        "        new_test = np.array(new_test)\n",
        "        new_test[new_test!=new_test]='0'\n",
        "        new_test = new_test.astype(int)\n",
        "        new_forest = RandomForestClassifier(n_estimators=nest,\n",
        "                                        criterion=criteria, \n",
        "                                        bootstrap=boot,\n",
        "                                        oob_score=oob,\n",
        "                                        max_features=modfeat,\n",
        "                                        random_state=RSEED, \n",
        "                                        n_jobs=-1)\n",
        "        new_forest.fit(new_features,ilabels)\n",
        "        #threshold = 0.42\n",
        "\n",
        "        predictions = new_forest.predict_proba(new_test)\n",
        "        predictions[:,0] = (predictions[:,0] < threshold).astype('int')\n",
        "        predictions = (predictions[:,1] >= threshold).astype('int')\n",
        "        all_predictions.append(predictions)\n",
        "    '''\n",
        "    uniques = []\n",
        "    features = pd.read_csv(base_dir + \"OHtraining/\" + loc + \"_train.csv\")\n",
        "    vfeatures = pd.read_csv(base_dir + \"OHtraining/\" + loc + \"_validation.csv\")\n",
        "    test = pd.read_csv(base_dir + \"OHtesting/\" + loc + \"_test.csv\")\n",
        "    features, sers = fix_data(uniques, features,loc,iset='training',ident='train')\n",
        "    vfeatures, vsers = fix_data(uniques, vfeatures,loc,iset='training',ident='validation')\n",
        "\n",
        "    test = test.drop('serology', axis=1)\n",
        "    test.to_csv(base_dir + 'randfor/testing/'+loc+'_test.csv', index=True)\n",
        "\n",
        "\n",
        "    features = features.append(vfeatures)\n",
        "    labels = np.array(features[vsers])\n",
        "    features = features.drop(vsers, axis=1)\n",
        "    features = features.reset_index()\n",
        "    indices = features[\"allele\"]\n",
        "    indices = list(indices)\n",
        "    features = features.drop('allele', axis=1)\n",
        "    feature_list = list(features.columns)\n",
        "    n_features = len(feature_list)\n",
        "    #maxfeat = int(math.sqrt(n_features))\n",
        "\n",
        "    features = np.array(features)\n",
        "    labels[labels!=labels]='0'\n",
        "    features[features!=features]='0'\n",
        "    features = features.astype(float)\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    test_idcs = test['allele']\n",
        "    test = test.drop('allele', axis=1)\n",
        "    #print(test.head(100))\n",
        "    test_list = list(test.columns)\n",
        "    test = np.array(test)\n",
        "    test[test!=test]='0'\n",
        "    test = test.astype(float)\n",
        "    ind_labels = [str(x) for x in sers]\n",
        "\n",
        "    all_predictions = []\n",
        "    for idx in range(0,len(ind_labels)):\n",
        "        ilabels = labels[:,idx]\n",
        "        forest = RandomForestClassifier(n_estimators=nest,\n",
        "                                        criterion=criteria, \n",
        "                                        bootstrap=boot,\n",
        "                                        oob_score=oob,\n",
        "                                        max_features=modfeat,\n",
        "                                        random_state=RSEED, \n",
        "                                        n_jobs=-1)\n",
        "        forest.fit(features,ilabels)\n",
        "        #predictions = forest.predict(test)\n",
        "        #print(predictions)\n",
        "\n",
        "        predictions = forest.predict_proba(test)\n",
        "        predictions[:,0] = (predictions[:,0] < threshold).astype('int')\n",
        "        predictions = (predictions[:,1] >= threshold).astype('int')\n",
        "        #print(predictions)\n",
        "        all_predictions.append(predictions)\n",
        "\n",
        "        # Feature Importance\n",
        "\n",
        "        importances = forest.feature_importances_\n",
        "        \n",
        "        std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "                    axis=0)\n",
        "        feat_indices = np.argsort(importances)[::-1]\n",
        "        nz_importances = importances[importances!=0]\n",
        "        nz_indices = feat_indices[:len(nz_importances)]\n",
        "    '''\n",
        "    all_predictions = np.asarray(all_predictions)\n",
        "    all_predictions = np.transpose(all_predictions)\n",
        "    preds_output = pd.DataFrame(all_predictions, index=test_idcs, columns=ind_labels)\n",
        "    preds_output = one_hot_decode(preds_output)\n",
        "    preds_output = preds_output.drop(ind_labels, axis=1)\n",
        "    preds_output.index.name = 'allele'\n",
        "    preds_output = preds_output.apply(lambda x: str((x['serology'].split(';'))[:-1]), result_type='broadcast', axis=1)\n",
        "    preds_output.to_csv(base_dir + 'predictions/'+loc+'_predictions.csv', index=True)\n",
        "\n",
        "\n",
        "    acc = pretest(loc)\n",
        "    if acc > prev_acc:\n",
        "        prev_acc = acc\n",
        "        print('accuracy:\\t{}'.format(str(prev_acc)))\n",
        "        return prev_acc, True\n",
        "    elif acc == prev_acc:\n",
        "        prev_acc = acc\n",
        "        print('accuracy:\\t{}'.format(str(prev_acc)))\n",
        "        return prev_acc, True\n",
        "    else:\n",
        "        prev_acc = acc\n",
        "        print('accuracy:\\t{}'.format(str(prev_acc)))\n",
        "        return prev_acc, False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LupZ6qWtm2Rw"
      },
      "source": [
        "### Contained Accuracy Checker for Threshold Finder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2xM90dAPfHKO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "loci = ['A', 'B', 'C', 'DQB1', 'DRB1']\n",
        "summary = {}\n",
        "\n",
        "# dict of dicts to store splits of broad specificities\n",
        "broad_split = {\n",
        "    \"A\" : {\n",
        "        \"9\" : [\"23\", \"24\"],\n",
        "        \"10\" : [\"25\", \"26\", \"34\", \"66\"],\n",
        "        \"19\" : [\"29\", \"30\", \"31\", \"32\", \"33\", \"74\"],\n",
        "        \"28\" : [\"68\", \"69\"]\n",
        "    },\n",
        "    \"B\" : {\n",
        "        \"5\" : [\"51\", \"52\"],\n",
        "        \"12\" : [\"44\", \"45\"],\n",
        "        \"14\" : [\"64\", \"65\"],\n",
        "        \"15\" : [\"62\", \"63\", \"75\", \"76\", \"77\"],\n",
        "        \"16\" : [\"38\", \"39\"],\n",
        "        \"17\" : [\"57\", \"58\"],\n",
        "        \"21\" : [\"49\", \"50\"],\n",
        "        \"22\" : [\"54\", \"55\", \"56\"],\n",
        "        \"40\" : [\"60\", \"61\"],\n",
        "        \"70\" : [\"71\", \"72\"]\n",
        "    },\n",
        "    \"C\" : {\n",
        "        \"3\" : [\"9\", \"10\"]\n",
        "    },\n",
        "    \"DQB1\" : {\n",
        "        \"1\" : [\"5\", \"6\"],\n",
        "        \"3\" : [\"7\", \"8\", \"9\"]\n",
        "    },\n",
        "    \"DRB1\" : {\n",
        "        \"2\" : [\"15\", \"16\"],\n",
        "        \"3\" : [\"17\", \"18\"],\n",
        "        \"5\" : [\"11\", \"12\"],\n",
        "        \"6\" : [\"13\", \"14\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# dict of dict to store broad specificity for each split\n",
        "split_broad = {}\n",
        "\n",
        "for alphakey in broad_split.keys():\n",
        "    sb = {}\n",
        "    \n",
        "    for betakey in broad_split[alphakey].keys():\n",
        "        for value in broad_split[alphakey][betakey]:\n",
        "            sb[value] = betakey\n",
        "    \n",
        "    split_broad[alphakey] = sb\n",
        "\n",
        "# function to check if value can be an integer - to eliminate excess characters from serology labels\n",
        "def checkInt(x):\n",
        "    try:\n",
        "        int(x)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "# function to eliminate any serological assignments with under a 95% likelihood\n",
        "def chance(x, line):\n",
        "    if (line[x].find(\"%\") != -1):\n",
        "        x = float(line[x][:-1])\n",
        "        if 51 <= x:\n",
        "            test = True\n",
        "        else:\n",
        "            test = False\n",
        "    else:\n",
        "        test = False\n",
        "    return test\n",
        "\n",
        " \n",
        "def evaluate(loc, p_allele, relser, right, wrong, partial, close, bad, broad_split=broad_split, split_broad=split_broad):\n",
        "    p_ser = str(p_allele.serology).replace(\"'\",'').replace('[','').replace(']','').replace('\"','').replace(',','')\n",
        "    p_ser = set(p_ser.split(' '))\n",
        "    \n",
        "    if p_allele.allele in relser.index:\n",
        "        newser = set(relser.loc[p_allele.allele].serology.split(' '))\n",
        "        if p_ser == newser:\n",
        "            right.append(p_allele.allele)\n",
        "        elif p_ser != newser:\n",
        "            wrong.append(p_allele.allele)\n",
        "            if any(w in newser for w in p_ser):\n",
        "                partial.append(p_allele.allele)\n",
        "            else:\n",
        "                switch1 = \"no\"\n",
        "                for oldval in p_ser:\n",
        "                    if (oldval in list(broad_split[loc].keys())) or (oldval in list(split_broad[loc].keys())):\n",
        "                        if oldval in list(broad_split[loc].keys()):\n",
        "                            if any(x in newser for x in broad_split[loc][oldval]):\n",
        "                                close.append(p_allele.allele)\n",
        "                                switch1 = \"yes\"\n",
        "                        elif oldval in list(split_broad[loc].keys()):\n",
        "                            if any(y in newser for y in split_broad[loc][oldval]):\n",
        "                                close.append(p_allele.allele)\n",
        "                                switch1 = \"yes\"\n",
        "                if switch1 == \"no\":\n",
        "                    bad.append(p_allele.allele)\n",
        "\n",
        "        return right, wrong, partial, close, bad\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        return right, wrong, partial, close, bad\n",
        "\n",
        "def met_pct(datalist, right, wrong, partial, close, bad):\n",
        "    n_alleles = len(datalist)\n",
        "    n_r = len(right)\n",
        "    n_w = len(wrong)\n",
        "    n_p = len(partial)\n",
        "    n_b = len(bad)\n",
        "\n",
        "    p_r = (n_r / n_alleles) * 100\n",
        "    p_w = (n_w / n_alleles) * 100\n",
        "    p_p = (n_p / n_alleles) * 100\n",
        "    p_b = (n_b / n_alleles) * 100\n",
        "\n",
        "    p_dict = {\n",
        "        \"All Calls Correct\" : p_r,\n",
        "        \"Incorrect\" : p_w,\n",
        "        \"At Least One Correct Call\" : p_p,\n",
        "        \"All Calls Incorrect\" : p_b,\n",
        "    }\n",
        "\n",
        "    return p_dict\n",
        "\n",
        "def accuracy(loc, dataframe, relser):\n",
        "    right = []\n",
        "    wrong = []\n",
        "    partial = []\n",
        "    close = []\n",
        "    bad = []\n",
        "\n",
        "    for all in dataframe.iloc:\n",
        "        # FIXME - A*23:19Q does not appear in rel_dna_ser (A*23:19N instead)\n",
        "        # FIXME - B*07:44 does not appear in rel_dna_ser (B*07:44N instead)\n",
        "        # FIXME - B*08:06 does not appear in rel_dna_ser at all\n",
        "        # FIXME - B*49:15 does not appear in rel_dna_ser at all\n",
        "        # FIXME - C*03:23 does not appear in rel_dna_ser (C*03:23N instead)\n",
        "        # FIXME - C*03:99 does not appear in rel_dna_ser at all\n",
        "        # FIXME - C*05:02 does not appear in rel_dna_ser at all\n",
        "        # FIXME - C*07:226 does not appear in rel_dna_ser (C*07:226Q instead)\n",
        "        if all.allele in [\"A*23:19Q\", \"B*07:44\", \"B*08:06\", \"B*49:15\", \"C*03:23\", \"C*03:99\", \"C*05:02\", \"C*07:226\"]:\n",
        "            continue\n",
        "        \n",
        "        right, wrong, partial, close, bad = evaluate(loc, all, relser, right, wrong, partial, close, bad)\n",
        "\n",
        "    df = relser[relser.index.isin(dataframe.allele)]\n",
        "\n",
        "    met_dict = met_pct(df, right, wrong, partial, close, bad)\n",
        "\n",
        "    return met_dict\n",
        "\n",
        "\n",
        "def check_acc_all(loc):\n",
        "    mets = {}\n",
        "\n",
        "    old_nn_preds = pd.read_csv(NN_dir+\"old-predictions/\"+loc+\"_predictions.csv\", dtype=str)\n",
        "    rf_preds = pd.read_csv(NN_dir+\"randomforest/predictions/\"+loc+\"_predictions.csv\", dtype=str)\n",
        "    rf_preds = rf_preds[rf_preds.allele.isin(old_nn_preds.allele)]\n",
        "    # added this filter to make sure all comparisons are identical\n",
        "    relser = pd.read_csv(NN_dir+\"ser/\"+loc+\"_ser.csv\", dtype=str)\n",
        "    relser = relser.set_index('allele')\n",
        "    relser = relser.dropna()\n",
        "\n",
        "    mets[loc] = accuracy(loc, rf_preds, relser)\n",
        "\n",
        "    return mets\n",
        "\n",
        "def pretest(loc):\n",
        "    mets = check_acc_all(loc)\n",
        "\n",
        "    return mets[loc]['All Calls Correct']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZrgFQIlXslC"
      },
      "source": [
        "### Script to Find Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NJAuTT-pi9At",
        "outputId": "35720b59-c57d-4734-e9ef-fb2f41a9b008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nest:\t55\t\tthreshold:\t0.42\t\tmodfeat:\t1\t\tnumfeat:\t25\t\taccuracy:\t51.42857142857142\n",
            "nest:\t55\t\tthreshold:\t0.5\t\tmodfeat:\t1\t\tnumfeat:\t25\t\t"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1368/1940997117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0;31m#print('nest:\\t\\t\\t{}...modfeat:\\t\\t\\t{}...'.format(str(nest),str(modfeat)),end='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nest:\\t{}\\t\\tthreshold:\\t{}\\t\\tmodfeat:\\t{}\\t\\tnumfeat:\\t{}\\t\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                         \u001b[0mprev_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mprev_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m74.00\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0mcont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_1368/584629322.py\u001b[0m in \u001b[0;36mpredict_sero\u001b[0;34m(loc, nest, boot, criteria, oob, modfeat, numfeat, threshold, i, prev_acc)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Feature/Permutation Importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m#feat_indices = np.argsort(forest.feature_importances_)[::-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtree_importance_sorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mtree_importance_sorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_importance_sorted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnumfeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.venvs/SERO/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         all_importances = Parallel(\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.venvs/SERO/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.venvs/SERO/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.venvs/SERO/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.venvs/SERO/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         return self._get_pool().apply_async(\n\u001b[0m\u001b[1;32m    253\u001b[0m             SafeFunction(func), callback=callback)\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.venvs/SERO/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m_get_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0mPool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_queues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "loc = 'DRB1'\n",
        "prev_acc = 0\n",
        "cont = True\n",
        "nest = 55\n",
        "boots = [True, False]\n",
        "criteria = 'gini'\n",
        "oobs = [True, False]\n",
        "thresholds = [0.42] #0.4\n",
        "numfeats = [50,100,200]\n",
        "#threshold = 0.42\n",
        "modfeats = [1,'log2','auto']\n",
        "#modfeat = 'log2'\n",
        "i = 0\n",
        "\n",
        "breaktime = False\n",
        "\n",
        "while cont:\n",
        "    if breaktime == True:\n",
        "        break\n",
        "    for oob in oobs:\n",
        "        if breaktime == True:\n",
        "            break\n",
        "        for boot in boots:\n",
        "            if breaktime == True:\n",
        "                break\n",
        "            for numfeat in numfeats:\n",
        "                if breaktime == True:\n",
        "                    break\n",
        "                for modfeat in modfeats:\n",
        "                    if breaktime == True:\n",
        "                        break\n",
        "                    for threshold in thresholds:\n",
        "                        if breaktime == True:\n",
        "                            break\n",
        "                        #print('nest:\\t\\t\\t{}...modfeat:\\t\\t\\t{}...'.format(str(nest),str(modfeat)),end='')\n",
        "                        print('round:\\t{}')\n",
        "                        print('nest:\\t{}\\t\\tthreshold:\\t{}\\t\\tmodfeat:\\t{}\\t\\tnumfeat:\\t{}\\t\\t'.format(str(nest),str(threshold),str(modfeat),str(numfeat)),end='')\n",
        "                        prev_acc, cont = predict_sero(loc, nest, boot, criteria, oob, modfeat, numfeat, threshold, i, prev_acc)\n",
        "                        if prev_acc > 74.00:\n",
        "                            cont = False\n",
        "                            breaktime = True\n",
        "                            break\n",
        "                        else:\n",
        "                            cont = True\n",
        "                        i += 1\n",
        "    nest += 1\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_OVKdcgMytD"
      },
      "source": [
        "## Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkLYt7iO1-33"
      },
      "outputs": [],
      "source": [
        "\n",
        "    '''\n",
        "    UEfeat = pd.read_csv(base_dir + \"training/\" + loc + \"_train.csv\")\n",
        "    UEvfeat = pd.read_csv(base_dir + \"training/\" + loc + \"_validation.csv\")\n",
        "    UEtest = pd.read_csv(base_dir + \"testing/\" + loc + \"_test.csv\")\n",
        "\n",
        "    updateFeat = add_data(UEfeat)\n",
        "    updateVFeat = add_data(UEvfeat)\n",
        "    updateTest = add_data(UEtest)\n",
        "    \n",
        "    features = pd.merge(features,updateFeat,how='left',on='allele')\n",
        "    vfeatures = pd.merge(vfeatures,updateVFeat,how='left',on='allele')\n",
        "    test = pd.merge(test,updateTest,how='left',on='allele')\n",
        "\n",
        "    features.to_csv(\"{}OHtraining/xtd{}_train.csv\".format(base_dir,loc), index=False)\n",
        "    vfeatures.to_csv(\"{}OHtraining/xtd{}_validation.csv\".format(base_dir,loc), index=False)\n",
        "    test.to_csv(\"{}OHtesting/xtd{}_test.csv\".format(base_dir,loc), index=False)\n",
        "    '''\n",
        "        '''\n",
        "        with open(base_dir+'feat_importance/'+loc+'-'+ind_labels[idx]+'_rank.txt', 'w+') as handle:\n",
        "            # Print the feature ranking\n",
        "            handle.write(\"Feature ranking: \\n\")\n",
        "            for x in range(features.shape[1]):\n",
        "                handle.write(\"%d. feature %s (%f)\\n\" % (x + 1, feature_list[indices[x]], importances[indices[x]]))\n",
        "\n",
        "        with open(base_dir+'feat_importance/'+loc+'-'+ind_labels[idx]+'_nzrank.txt', 'w+') as handle:\n",
        "            # Print the feature ranking\n",
        "            handle.write(\"Feature ranking: \\n\")\n",
        "            for y in range(len(nz_indices)):\n",
        "                handle.write(\"%d. feature %s (%f)\\n\" % (y + 1, feature_list[nz_indices[y]], importances[nz_indices[y]]))\n",
        "\n",
        "        # Plot the impurity-based feature importances of the forest\n",
        "        f = plt.figure()\n",
        "        plt.title(\"Feature importances\")\n",
        "        #plt.bar(range(features.shape[1]), importances[indices],\n",
        "        #        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "        #\n",
        "        #plt.xticks(range(features.shape[1]), indices)\n",
        "        #plt.xlim([-1, features.shape[1]])\n",
        "        \n",
        "        plt.bar(range(len(nz_indices)), importances[nz_indices],\n",
        "                color=\"r\", yerr=std[nz_indices], align=\"center\")\n",
        "        nzlabs = [feature_list[nz_indices[i]] for i in range(0, len(nz_indices))] \n",
        "        plt.xticks(range(len(nz_indices)), nzlabs, rotation='vertical', fontsize=3) \n",
        "        plt.xlim([-1, len(nz_indices)])\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        \n",
        "        #plt.show()\n",
        "        #f = plt.figure()\n",
        "        f.savefig(base_dir+'feat_importance/'+loc+'-'+ind_labels[idx]+\"_nz.pdf\", bbox_inches='tight')\n",
        "\n",
        "        plt.bar(range(features.shape[1]), importances[indices],\n",
        "                color=\"r\", yerr=std[indices], align=\"center\")  \n",
        "        labs = [feature_list[indices[j]] for j in range(0, len(indices))]\n",
        "        plt.xticks(range(features.shape[1]), labs, rotation='vertical', fontsize=3)\n",
        "        plt.xlim([-1, features.shape[1]])\n",
        "        plt.tight_layout()\n",
        "        f.savefig(base_dir+'feat_importance/'+loc+'-'+ind_labels[idx]+\".pdf\", bbox_inches='tight')\n",
        "        plt.close('all')\n",
        "        '''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iGaDga8MXUX7",
        "2ZHlTkNIXZQ_",
        "ueiWDlDFW84T",
        "qHfBpAisqYP8",
        "S_OVKdcgMytD"
      ],
      "name": "rf_sero.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1165788a06454a3e8aaf701b036c082e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16c61bd0779044e28edbf2243c8c45e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57cf106b7f4d4082a9e1ad04691657ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb757ca9eb347d79b9367ac54ae2788": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75dcc6134af644c88a4fcfb2fc937717": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6bcfb69dd5474e970ffa4951548279",
            "placeholder": "​",
            "style": "IPY_MODEL_6cb757ca9eb347d79b9367ac54ae2788",
            "value": "  0%"
          }
        },
        "83272967180c4ece8636a2d6bbdb1277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c61bd0779044e28edbf2243c8c45e5",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6b4ce5ccc82490ea88e279a1708c0fb",
            "value": 0
          }
        },
        "978018f7713b4b818160950f0cb193d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd75460274d64fb696529d6bfe59cebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_978018f7713b4b818160950f0cb193d5",
            "placeholder": "​",
            "style": "IPY_MODEL_57cf106b7f4d4082a9e1ad04691657ef",
            "value": " 0/5 [07:57&lt;?, ?it/s]"
          }
        },
        "cb6bcfb69dd5474e970ffa4951548279": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce001623c7504098ac23de019b0781d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75dcc6134af644c88a4fcfb2fc937717",
              "IPY_MODEL_83272967180c4ece8636a2d6bbdb1277",
              "IPY_MODEL_bd75460274d64fb696529d6bfe59cebd"
            ],
            "layout": "IPY_MODEL_1165788a06454a3e8aaf701b036c082e"
          }
        },
        "e6b4ce5ccc82490ea88e279a1708c0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
